"""
Servi√ßo Completo de IA para Suporte Emocional - Vers√£o Modular
Inclui: An√°lise de Sentimentos, Gera√ß√£o de Respostas, RAG e Sistema de Prompts

"""

import json
import os
import logging
import random
from datetime import datetime, UTC
from typing import Dict, List, Optional
from sqlalchemy import text

try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

# === DEPEND√äNCIAS OPCIONAIS ===
try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False


try:
    from transformers import pipeline
    BERT_AVAILABLE = True
except ImportError:
    BERT_AVAILABLE = False


# === IMPORTAR SISTEMA DE PROMPTS CONSOLIDADO ===
from .ai_prompt import AIPromptManager, PromptContext, RiskLevel, PromptType

# === IMPORTAR SISTEMAS AVAN√áADOS ===
from .finetuning_preparator import finetuning_preparator

# Configurar logging
logger = logging.getLogger(__name__)


class SimpleRAG:
    """
    Sistema RAG (Retrieval-Augmented Generation) Completo e Consolidado
    
    Funcionalidades:
    - Busca conversas similares bem-sucedidas no banco
    - Extra√ß√£o inteligente de palavras-chave
    - Ranking por relev√¢ncia com m√∫ltiplos fatores
    - Busca em dados de treinamento
    - Context enhancement para diferentes tipos de consulta
    - Cache para otimiza√ß√£o de performance
    - Sistema unificado (substitui advanced_rag_service)
    """
    
    def __init__(self):
        """Inicializa o sistema RAG consolidado"""
        self.cache = {}  # Cache simples mas eficaz
        self.training_cache = {}  # Cache para dados de treinamento
        logger.info("SimpleRAG consolidado inicializado")
    
    def get_relevant_context(self, user_message: str, risk_level: str = 'low', 
                           limit: int = 3) -> Optional[str]:
        print(f"[RAG] Buscando contexto para: '{user_message}' | Risco: {risk_level} | Limite: {limit}")
        """
        Busca contexto relevante de conversas bem-sucedidas
        
        Args:
            user_message: Mensagem do usu√°rio
            risk_level: N√≠vel de risco (low, moderate, high, critical)
            limit: N√∫mero m√°ximo de exemplos a retornar
            
        Returns:
            String com contexto relevante ou None se n√£o encontrar
        """
        try:
            # Verificar cache primeiro
            cache_key = f"{hash(user_message)}_{risk_level}_{limit}"
            if cache_key in self.cache:
                print(f"[RAG] Contexto encontrado no cache.")
                return self.cache[cache_key]

            # Extrair palavras-chave da mensagem
            keywords = self._extract_keywords(user_message)
            print(f"[RAG] Palavras-chave extra√≠das: {keywords}")

            # Buscar conversas similares
            similar_conversations = self._find_similar_conversations(keywords, risk_level, limit * 2)
            print(f"[RAG] Conversas similares encontradas: {len(similar_conversations)}")

            # Ranquear por relev√¢ncia
            ranked_conversations = self._rank_conversations(similar_conversations, user_message)
            print(f"[RAG] Conversas ranqueadas: {len(ranked_conversations)}")

            # Construir contexto a partir das melhores
            context = self._build_context(ranked_conversations[:limit])
            print(f"[RAG] Contexto final gerado: {'Sim' if context else 'N√£o'}")

            # Cachear resultado
            self.cache[cache_key] = context

            return context

        except Exception as e:
            logger.error(f"Erro no RAG: {e}")
            print(f"[RAG] Erro: {e}")
            return None
    
    def _extract_keywords(self, text: str) -> List[str]:
        """Extrai palavras-chave relevantes para sa√∫de mental"""
        mental_health_keywords = [
            'ansiedade', 'depress√£o', 'tristeza', 'medo', 'preocupa√ß√£o',
            'estresse', 'p√¢nico', 'ang√∫stia', 'solid√£o', 'vazio', 'raiva',
            'trabalho', 'fam√≠lia', 'relacionamento', 'escola', 'faculdade',
            'dinheiro', 'sa√∫de', 'futuro', 'passado', 'culpa', 'frustra√ß√£o'
        ]
        
        text_lower = text.lower()
        found_keywords = []
        
        # Buscar palavras-chave espec√≠ficas
        for keyword in mental_health_keywords:
            if keyword in text_lower:
                found_keywords.append(keyword)
        
        # Adicionar palavras importantes do texto (> 4 caracteres)
        words = [w for w in text_lower.split() if len(w) > 4 and w.isalpha()]
        found_keywords.extend(words[:5])
        
        return list(set(found_keywords))[:10]  # Remover duplicatas e limitar
    
    def _find_similar_conversations(self, keywords: List[str], risk_level: str, 
                                  limit: int = 10) -> List[Dict]:
        print(f"[RAG] Buscando conversas no banco. Keywords: {keywords} | Limite: {limit}")
        """Busca conversas similares no banco de dados priorizando s√≥ palavras-chave e avalia√ß√£o, sem filtrar por risco"""
        try:
            from app import db
            if keywords:
                keyword_pattern = '|'.join([k for k in keywords if len(k) > 3])
            else:
                keyword_pattern = ''
            # 1. Busca com keywords (qualquer risco)
            query = text("""
                SELECT DISTINCT
                    cm_user.content as user_message,
                    cm_ai.content as ai_response,
                    cs.user_rating,
                    cs.initial_risk_level,
                    cm_ai.created_at
                FROM chat_sessions cs
                JOIN chat_messages cm_user ON cs.id = cm_user.session_id 
                    AND cm_user.message_type = 'USER'
                JOIN chat_messages cm_ai ON cs.id = cm_ai.session_id 
                    AND cm_ai.message_type = 'AI'
                    AND cm_ai.id > cm_user.id
                WHERE 
                    cs.user_rating >= 4
                    AND (:keyword_pattern = '' OR cm_user.content ~* :keyword_pattern)
                    AND cm_user.created_at >= NOW() - INTERVAL '6 months'
                    AND LENGTH(cm_user.content) > 10
                    AND LENGTH(cm_ai.content) > 20
                ORDER BY cs.user_rating DESC, cm_ai.created_at DESC
                LIMIT :limit
            """)
            result = db.session.execute(query, {
                'keyword_pattern': keyword_pattern,
                'limit': limit
            })
            rows = [dict(row._mapping) for row in result]
            print(f"[RAG] Linhas retornadas do banco (keywords): {len(rows)}")
            if rows:
                return rows
            # 2. √öltima tentativa: pega os √∫ltimos registros bem avaliados
            query = text("""
                SELECT DISTINCT
                    cm_user.content as user_message,
                    cm_ai.content as ai_response,
                    cs.user_rating,
                    cs.initial_risk_level,
                    cm_ai.created_at
                FROM chat_sessions cs
                JOIN chat_messages cm_user ON cs.id = cm_user.session_id 
                    AND cm_user.message_type = 'USER'
                JOIN chat_messages cm_ai ON cs.id = cm_ai.session_id 
                    AND cm_ai.message_type = 'AI'
                    AND cm_ai.id > cm_user.id
                WHERE 
                    cs.user_rating >= 4
                    AND cm_user.created_at >= NOW() - INTERVAL '6 months'
                    AND LENGTH(cm_user.content) > 10
                    AND LENGTH(cm_ai.content) > 20
                ORDER BY cs.user_rating DESC, cm_ai.created_at DESC
                LIMIT :limit
            """)
            result = db.session.execute(query, {
                'limit': limit
            })
            rows = [dict(row._mapping) for row in result]
            print(f"[RAG] Linhas retornadas do banco (s√≥ √∫ltimos): {len(rows)}")
            return rows
        except Exception as e:
            logger.error(f"Erro na busca de conversas: {e}")
            print(f"[RAG] Erro: {e}")
            return []
    
    def _rank_conversations(self, conversations: List[Dict], user_message: str) -> List[Dict]:
        """Ranqueia conversas por relev√¢ncia"""
        if not conversations:
            return []
        
        user_words = set(user_message.lower().split())
        
        for conv in conversations:
            try:
                conv_words = set(conv['user_message'].lower().split())
                common_words = len(user_words.intersection(conv_words))
                word_similarity = common_words / max(len(user_words), 1)
                rating_score = (conv.get('user_rating', 3)) / 5.0
                
                # Score final ponderado
                conv['relevance_score'] = (word_similarity * 0.6) + (rating_score * 0.4)
                
            except Exception:
                conv['relevance_score'] = 0
        
        conversations.sort(key=lambda x: x.get('relevance_score', 0), reverse=True)
        return conversations
    
    def _build_context(self, conversations: List[Dict]) -> Optional[str]:
        """Constr√≥i contexto formatado a partir das melhores conversas"""
        if not conversations:
            return None
        
        context_parts = ["EXEMPLOS DE RESPOSTAS EFICAZES:\n"]
        
        for i, conv in enumerate(conversations, 1):
            user_msg = conv['user_message'][:120]
            ai_response = conv['ai_response'][:200]
            rating = conv.get('user_rating', 0)
            
            context_parts.append(
                f"Exemplo {i} (‚≠ê{rating}/5):\n"
                f"Situa√ß√£o: {user_msg}{'...' if len(conv['user_message']) > 120 else ''}\n"
                f"Resposta eficaz: {ai_response}{'...' if len(conv['ai_response']) > 200 else ''}\n"
            )
        
        context_parts.append("\nüí° Use como inspira√ß√£o, mas personalize para o contexto atual.")
        return "\n".join(context_parts)
    
    # === M√âTODOS AVAN√áADOS (CONSOLIDADOS DO ADVANCED RAG SERVICE) ===
    
    def get_enhanced_context(self, user_message: str, risk_level: str, 
                           context_type: str = 'all', limit: int = 3) -> Dict:
        """
        M√©todo avan√ßado para buscar contexto enriquecido
        
        Args:
            user_message: Mensagem do usu√°rio
            risk_level: N√≠vel de risco
            context_type: Tipo de contexto ('all', 'conversations', 'training')
            limit: Limite de resultados
            
        Returns:
            Dict com contexto_prompt, training_data e conversation_examples
        """
        try:
            result = {
                'context_prompt': '',
                'training_data': [],
                'conversation_examples': []
            }
            
            # Buscar conversas se solicitado
            if context_type in ['all', 'conversations']:
                conversation_context = self.get_relevant_context(user_message, risk_level, limit)
                if conversation_context:
                    result['context_prompt'] += conversation_context
                    result['conversation_examples'] = self._get_conversation_examples(user_message, risk_level, limit)
            
            # Buscar dados de treinamento se solicitado
            if context_type in ['all', 'training']:
                training_context = self._get_training_context(user_message, risk_level, limit)
                if training_context:
                    result['context_prompt'] += f"\n\n{training_context}"
                    result['training_data'] = self._get_training_data_details(user_message, limit)
            
            return result
            
        except Exception as e:
            logger.error(f"Erro no enhanced context: {e}")
            return {'context_prompt': '', 'training_data': [], 'conversation_examples': []}
    
    def search_training_content(self, query: str, limit: int = 5) -> List[Dict]:
        """
        Busca conte√∫do de treinamento baseado na query
        
        Args:
            query: Consulta de busca
            limit: Limite de resultados
            
        Returns:
            Lista de dicion√°rios com conte√∫do encontrado
        """
        try:
            cache_key = f"training_search_{hash(query)}_{limit}"
            if cache_key in self.training_cache:
                return self.training_cache[cache_key]
            
            # Implementa√ß√£o simples de busca em training data
            # Aqui voc√™ pode expandir para buscar em diferentes fontes
            keywords = self._extract_keywords(query)
            
            # Buscar em sess√µes de alta qualidade como "dados de treinamento"
            training_results = self._find_training_like_content(keywords, limit)
            
            self.training_cache[cache_key] = training_results
            return training_results
            
        except Exception as e:
            logger.error(f"Erro na busca de training content: {e}")
            return []
    
    def get_training_data_statistics(self) -> Dict:
        """
        Retorna estat√≠sticas dos dados de treinamento/RAG
        
        Returns:
            Dict com estat√≠sticas do sistema
        """
        try:
            from app import db
            
            # Estat√≠sticas de conversas bem-sucedidas
            conv_stats_query = text("""
                SELECT 
                    COUNT(*) as total_sessions,
                    AVG(user_rating) as avg_rating,
                    COUNT(CASE WHEN user_rating >= 4 THEN 1 END) as high_quality_sessions
                FROM chat_sessions 
                WHERE user_rating IS NOT NULL
                    AND created_at >= NOW() - INTERVAL '6 months'
            """)
            
            result = db.session.execute(conv_stats_query).first()
            
            return {
                'total_conversations': int(result.total_sessions) if result else 0,
                'average_rating': float(result.avg_rating) if result and result.avg_rating else 0,
                'high_quality_conversations': int(result.high_quality_sessions) if result else 0,
                'cache_size': len(self.cache),
                'training_cache_size': len(self.training_cache),
                'system_type': 'consolidated_rag'
            }
            
        except Exception as e:
            logger.error(f"Erro ao obter estat√≠sticas: {e}")
            return {
                'total_conversations': 0,
                'average_rating': 0,
                'high_quality_conversations': 0,
                'cache_size': len(self.cache),
                'training_cache_size': len(self.training_cache),
                'system_type': 'consolidated_rag',
                'error': str(e)
            }
    
    def _get_conversation_examples(self, user_message: str, risk_level: str, limit: int) -> List[Dict]:
        print(f"[RAG] Obtendo exemplos de conversas para: '{user_message}' | Risco: {risk_level} | Limite: {limit}")
        """Obt√©m exemplos de conversas formatados para o sistema de prompts"""
        try:
            conversations = self._find_similar_conversations(
                self._extract_keywords(user_message), 
                risk_level, 
                limit
            )
            
            examples = []
            for conv in conversations[:limit]:
                examples.append({
                    'user_message': conv['user_message'],
                    'ai_response': conv['ai_response'],
                    'rating': conv.get('user_rating', 3),
                    'risk_level': conv.get('initial_risk_level', 'moderate')
                })
            
            print(f"[RAG] Exemplos de conversas retornados: {len(examples)}")
            return examples
            
        except Exception as e:
            logger.error(f"Erro ao obter exemplos: {e}")
            return []
    
    def _get_training_context(self, user_message: str, risk_level: str, limit: int) -> Optional[str]:
        """Constr√≥i contexto baseado em dados de treinamento"""
        try:
            training_data = self.search_training_content(user_message, limit)
            
            if not training_data:
                return None
            
            context_parts = ["CONHECIMENTO DE TREINAMENTO RELEVANTE:\n"]
            
            for i, item in enumerate(training_data, 1):
                context_parts.append(
                    f"Situa√ß√£o {i}: {item.get('situation', '')}[:150]\n"
                    f"Abordagem recomendada: {item.get('approach', '')}[:200]\n"
                )
            
            context_parts.append("\nüí° Aplique este conhecimento ao contexto espec√≠fico do usu√°rio.")
            return "\n".join(context_parts)
            
        except Exception as e:
            logger.error(f"Erro no contexto de treinamento: {e}")
            return None
    
    def _get_training_data_details(self, user_message: str, limit: int) -> List[Dict]:
        """Obt√©m detalhes dos dados de treinamento para contexto avan√ßado"""
        return self.search_training_content(user_message, limit)
    
    def _find_training_like_content(self, keywords: List[str], limit: int) -> List[Dict]:
        """
        Busca conte√∫do que pode servir como dados de treinamento
        (conversas de alta qualidade, casos bem documentados, etc.)
        """
        try:
            from app import db
            
            if keywords:
                keyword_pattern = '|'.join([k for k in keywords if len(k) > 3])
            else:
                keyword_pattern = ''
            
            # Buscar conversas muito bem avaliadas como "dados de treinamento"
            query = text("""
                SELECT 
                    cm_user.content as situation,
                    cm_ai.content as approach,
                    cs.user_rating,
                    cs.initial_risk_level,
                    'high_quality_conversation' as source_type
                FROM chat_sessions cs
                JOIN chat_messages cm_user ON cs.id = cm_user.session_id 
                    AND cm_user.message_type = 'USER'
                JOIN chat_messages cm_ai ON cs.id = cm_ai.session_id 
                    AND cm_ai.message_type = 'AI'
                    AND cm_ai.id > cm_user.id
                WHERE 
                    cs.user_rating = 5  -- Apenas conversas perfeitas
                    AND (:keyword_pattern = '' OR cm_user.content ~* :keyword_pattern)
                    AND LENGTH(cm_user.content) > 15
                    AND LENGTH(cm_ai.content) > 30
                ORDER BY cs.created_at DESC
                LIMIT :limit
            """)
            
            result = db.session.execute(query, {
                'keyword_pattern': keyword_pattern,
                'limit': limit
            })
            
            return [dict(row._mapping) for row in result]
            
        except Exception as e:
            logger.error(f"Erro na busca de training-like content: {e}")
            return []


class AIService:
    """
    Servi√ßo Completo de IA para Suporte Emocional
    
    Funcionalidades principais:
    - An√°lise de sentimentos com OpenAI
    - Avalia√ß√£o de n√≠veis de risco integrada
    - Gera√ß√£o de respostas emp√°ticas contextualizadas  
    - Sistema RAG para melhor qualidade
    - Sistema de prompts modular e manuten√≠vel
    - Fallback para m√∫ltiplos modelos
    - Cache e otimiza√ß√µes de performance
    
    Vers√£o: 2.1 - Modular com Prompt Manager Separado
    """
    
    def __init__(self, app=None):
        """
        Inicializa o servi√ßo de IA com todas as funcionalidades
        
        Args:
            app: Inst√¢ncia da aplica√ß√£o Flask (opcional)
        """
        self.app = app
        
        # === CONFIGURA√á√ÉO OPENAI (Principal) ===
        self.openai_client = None
        self.openai_model = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
        self.max_tokens = int(os.getenv("OPENAI_MAX_TOKENS", 300))
        self.temperature = float(os.getenv("OPENAI_TEMPERATURE", 0.5))
        
        openai_api_key = os.getenv("OPENAI_API_KEY")
        if openai_api_key:
            self.openai_client = openai
            self.openai_client.api_key = openai_api_key
            print(f"[INFO] OpenAI configurado | Modelo: {self.openai_model} | Temperatura: {self.temperature}")
        else:
            logger.warning("OpenAI API key n√£o encontrada")
        
        # === CONFIGURA√á√ÉO GEMINI (Fallback) ===
        self.gemini_client = None
        self.gemini_model = os.getenv("GEMINI_MODEL", "gemini-pro")
        
        if GEMINI_AVAILABLE:
            gemini_api_key = os.getenv("GEMINI_API_KEY")
            if gemini_api_key:
                try:
                    genai.configure(api_key=gemini_api_key)
                    self.gemini_client = genai
                    logger.info("Gemini configurado como fallback")
                except Exception as e:
                    logger.error(f"Erro ao configurar Gemini: {e}")
        

        
        # === SISTEMA RAG CONSOLIDADO ===
        self.rag = SimpleRAG()  # Sistema RAG unificado e completo
        self.rag_enabled = True
        # Alias para compatibilidade - aponta para o mesmo sistema consolidado
        self.advanced_rag = self.rag
        
        # === SISTEMA DE PROMPTS CONSOLIDADO ===
        self.prompt_manager = AIPromptManager()  # Sistema unificado de prompts
        
        # === SISTEMA DE FINE-TUNING ===
        self.finetuning_preparator = finetuning_preparator
        
        # === SISTEMA DE LOGGING DE TREINAMENTO ===
        self.log_training_usage = False  # Desabilitado - logger n√£o dispon√≠vel
        
        # === CACHE E OTIMIZA√á√ïES ===
        self.response_cache = {}
        self.cache_max_size = 100
        
        logger.info("AIService v2.0 inicializado com sucesso")
    
    def analyze_sentiment(self, text: str) -> Dict:
        """
        Analisa o sentimento do texto usando OpenAI com fallback inteligente
        Garante que o prompt pe√ßa resposta JSON, faz print do retorno e trata erro de parsing.
        """
        if not self.openai_client:
            return self._basic_sentiment_analysis(text)

        try:
            # Prompt expl√≠cito para resposta JSON
            system_content = (
                "Voc√™ √© um analisador de sentimentos. Analise a mensagem do usu√°rio e responda estritamente neste formato JSON: "
                '{"score": float, "confidence": float, "emotion": "...", "intensity": "..."}'
                "\nN√£o adicione explica√ß√µes, apenas o JSON."
            )
            response = self.openai_client.chat.completions.create(
                model=self.openai_model,
                messages=[
                    {"role": "system", "content": system_content},
                    {"role": "user", "content": f"Mensagem: {text}"}
                ],
                max_tokens=150,
                temperature=0.3
            )
            content = response.choices[0].message.content.strip()
            print(f"[OpenAI Sentiment Raw]: {content}")
            try:
                result = json.loads(content)
            except Exception as e:
                logger.error(f"Erro ao fazer parse do JSON retornado pela OpenAI: {e} | Conte√∫do: {content}")
                return self._basic_sentiment_analysis(text)

            # Validar resultado
            if all(key in result for key in ['score', 'confidence', 'emotion', 'intensity']):
                return result
            else:
                return self._basic_sentiment_analysis(text)

        except Exception as e:
            logger.error(f"Erro na an√°lise OpenAI: {e}")
            return self._basic_sentiment_analysis(text)
    
    def _basic_sentiment_analysis(self, text: str) -> Dict:
        """An√°lise b√°sica de sentimento como fallback"""
        text_lower = text.lower()
        
        positive_words = ['bem', 'bom', 'feliz', 'alegre', '√≥timo', 'amor', 'paz']
        negative_words = ['mal', 'ruim', 'triste', 'deprimido', '√≥dio', 'raiva', 'medo']
        critical_words = ['morrer', 'matar', 'suic√≠dio', 'acabar', 'desistir']
        
        positive_count = sum(1 for word in positive_words if word in text_lower)
        negative_count = sum(1 for word in negative_words if word in text_lower)
        critical_count = sum(1 for word in critical_words if word in text_lower)
        
        total_words = max(len(text_lower.split()), 1)
        score = (positive_count - negative_count - critical_count * 2) / total_words
        score = max(-1, min(1, score))
        
        if critical_count > 0:
            emotion, intensity = 'desesperado', 'high'
        elif score < -0.3:
            emotion = 'triste'
            intensity = 'high' if score < -0.6 else 'moderate'
        elif score > 0.3:
            emotion, intensity = 'feliz', 'moderate'
        else:
            emotion, intensity = 'neutro', 'low'
        
        return {
            'score': score,
            'confidence': 0.6,
            'emotion': emotion,
            'intensity': intensity
        }
    
    def assess_risk_level(self, text: str, sentiment_analysis: Optional[Dict] = None) -> str:
        """
        Avalia n√≠vel de risco usando RiskAnalyzer integrado
        
        Args:
            text: Texto para an√°lise
            sentiment_analysis: An√°lise de sentimento pr√©via (opcional)
            
        Returns:
            N√≠vel de risco: 'low', 'moderate', 'high', 'critical'
        """
        try:
            from app.services.risk_analyzer import RiskAnalyzer
            risk_analyzer = RiskAnalyzer()
            analysis = risk_analyzer.analyze_message(text)
            return analysis.get('risk_level', 'low')
        except ImportError:
            logger.warning("RiskAnalyzer n√£o dispon√≠vel, usando an√°lise b√°sica")
            return self._basic_risk_assessment(text, sentiment_analysis)
    
    def _basic_risk_assessment(self, text: str, sentiment_analysis: Optional[Dict] = None) -> str:
        """Avalia√ß√£o b√°sica de risco como fallback, com prints de debug"""
        text_lower = text.lower()

        critical_keywords = [
            'me matar', 'suic√≠dio', 'quero morrer', 'acabar com tudo',
            'n√£o quero viver', 'melhor morto',
            # Frases indiretas de idea√ß√£o suicida
            'n√£o ta fazendo muito sentido ficar aqui',
            'n√£o faz sentido continuar',
            'n√£o vejo mais sentido',
            'n√£o quero mais estar aqui',
            'preferia n√£o existir',
            'n√£o aguento mais viver',
            'cansei de tudo',
            'n√£o vejo sa√≠da',
            'n√£o vejo esperan√ßa',
            'n√£o vejo motivo pra continuar'
        ]

        high_keywords = [
            'n√£o aguento mais', 'desesperado', 'sem esperan√ßa', 'vazio total',
            'depress√£o severa', 'ansiedade extrema'
        ]

        moderate_keywords = [
            'triste', 'ansioso', 'preocupado', 'dif√≠cil', 'problema', 'ajuda'
        ]

        found_critical = [k for k in critical_keywords if k in text_lower]
        found_high = [k for k in high_keywords if k in text_lower]
        found_moderate = [k for k in moderate_keywords if k in text_lower]

        print(f"[RISK DEBUG] Texto: '{text}'")
        print(f"[RISK DEBUG] Palavras cr√≠ticas encontradas: {found_critical}")
        print(f"[RISK DEBUG] Palavras high encontradas: {found_high}")
        print(f"[RISK DEBUG] Palavras moderate encontradas: {found_moderate}")

        # Verificar palavras cr√≠ticas e frases indiretas
        if found_critical:
            print("[RISK DEBUG] Risco atribu√≠do: critical (palavra cr√≠tica)")
            return 'critical'

        # Usar an√°lise de sentimento se dispon√≠vel
        if sentiment_analysis:
            score = sentiment_analysis.get('score', 0)
            emotion = sentiment_analysis.get('emotion', '')
            print(f"[RISK DEBUG] An√°lise de sentimento: score={score}, emotion={emotion}")
            if emotion == 'desesperado' or score < -0.8:
                print("[RISK DEBUG] Risco atribu√≠do: critical (sentimento)")
                return 'critical'
            elif score < -0.5:
                print("[RISK DEBUG] Risco atribu√≠do: high (sentimento)")
                return 'high'

        # Verificar outras palavras-chave
        if found_high:
            print("[RISK DEBUG] Risco atribu√≠do: high (palavra high)")
            return 'high'

        if found_moderate:
            print("[RISK DEBUG] Risco atribu√≠do: moderate (palavra moderate)")
            return 'moderate'

        print("[RISK DEBUG] Risco atribu√≠do: low (nenhum match)")
        return 'low'
        
        # Verificar palavras cr√≠ticas
        for keyword in critical_keywords:
            if keyword in text_lower:
                return 'critical'
        
        # Usar an√°lise de sentimento se dispon√≠vel
        if sentiment_analysis:
            score = sentiment_analysis.get('score', 0)
            emotion = sentiment_analysis.get('emotion', '').lower()
            intensity = sentiment_analysis.get('intensity', '').lower()
            
            if emotion == 'desesperado' and intensity == 'high':
                return 'critical'
            elif emotion in ['triste', 'vazio'] and intensity == 'high' and score < -0.7:
                return 'high'
        
        # Verificar outras palavras-chave
        for keyword in high_keywords:
            if keyword in text_lower:
                return 'high'
        
        for keyword in moderate_keywords:
            if keyword in text_lower:
                return 'moderate'
        
        return 'low'
    
    def analyze_with_risk_assessment(self, text: str) -> Dict:
        """
        An√°lise completa: sentimento + risco em uma chamada otimizada
        
        Args:
            text: Texto para an√°lise completa
            
        Returns:
            Dict com an√°lise completa
        """
        try:
            # Verificar cache primeiro
            cache_key = f"analysis_{hash(text)}"
            if cache_key in self.response_cache:
                return self.response_cache[cache_key]
            
            # An√°lise de sentimento
            sentiment_result = self.analyze_sentiment(text)
            
            # Avalia√ß√£o de risco
            risk_level = self.assess_risk_level(text, sentiment_result)
            
            # Combinar resultados
            sentiment_result.update({
                'risk_level': risk_level,
                'requires_attention': risk_level in ['high', 'critical'],
                'timestamp': datetime.now(UTC).isoformat()
            })
            
            # Cachear resultado
            self._cache_result(cache_key, sentiment_result)
            
            return sentiment_result
            
        except Exception as e:
            logger.error(f"Erro na an√°lise completa: {e}")
            return {
                'score': 0,
                'confidence': 0.1,
                'emotion': 'neutro',
                'intensity': 'low',
                'risk_level': self.assess_risk_level(text),
                'requires_attention': False,
                'error': str(e),
                'timestamp': datetime.now(UTC).isoformat()
            }
    
    def analyze_diary_entry(self, entry_content: str) -> Optional[Dict]:
        """
        Analisa uma entrada do di√°rio para extrair insights emocionais
        
        Args:
            entry_content: Conte√∫do da entrada do di√°rio
            
        Returns:
            Dict com an√°lise da entrada ou None em caso de erro
        """
        try:
            if not entry_content or not entry_content.strip():
                return None
            
            # An√°lise de sentimento b√°sica
            sentiment_result = self.analyze_sentiment(entry_content)
            
            # Detectar emo√ß√µes espec√≠ficas usando palavras-chave
            emotions = self._detect_emotions_in_text(entry_content)
            
            # Identificar indicadores de risco
            risk_indicators = self._identify_risk_indicators(entry_content)
            
            # Extrair temas principais
            themes = self._extract_themes(entry_content)
            
            # Compilar an√°lise completa
            analysis = {
                'sentiment_score': sentiment_result.get('score', 0),
                'primary_emotion': sentiment_result.get('emotion', 'neutro'),
                'emotional_intensity': sentiment_result.get('intensity', 'low'),
                'detected_emotions': emotions,
                'risk_indicators': risk_indicators,
                'main_themes': themes,
                'analysis_timestamp': datetime.now(UTC).isoformat(),
                'word_count': len(entry_content.split()),
                'requires_attention': len(risk_indicators) > 0 or sentiment_result.get('score', 0) < -0.6
            }
            
            return analysis
            
        except Exception as e:
            logger.error(f"Erro na an√°lise do di√°rio: {e}")
            return None
    
    def _detect_emotions_in_text(self, text: str) -> List[str]:
        """Detecta emo√ß√µes espec√≠ficas no texto usando palavras-chave"""
        emotion_keywords = {
            'alegria': ['feliz', 'alegre', 'contente', 'animado', 'euf√≥rico', 'radiante', 'otimista'],
            'tristeza': ['triste', 'melanc√≥lico', 'deprimido', 'abatido', 'desanimado', 'lamentando'],
            'ansiedade': ['ansioso', 'nervoso', 'preocupado', 'inquieto', 'apreensivo', 'tenso'],
            'raiva': ['raiva', 'irritado', 'furioso', 'bravo', 'indignado', 'revoltado'],
            'medo': ['medo', 'amedrontado', 'assustado', 'aterrorizado', 'receoso'],
            'gratid√£o': ['grato', 'agradecido', 'reconhecido', 'aben√ßoado'],
            'amor': ['amor', 'carinho', 'afeto', 'paix√£o', 'adora√ß√£o'],
            'esperan√ßa': ['esperan√ßa', 'esperan√ßoso', 'confiante', 'positivo'],
            'solid√£o': ['sozinho', 'isolado', 'abandonado', 'solit√°rio'],
            'culpa': ['culpa', 'culpado', 'arrependido', 'remorso']
        }
        
        text_lower = text.lower()
        detected_emotions = []
        
        for emotion, keywords in emotion_keywords.items():
            if any(keyword in text_lower for keyword in keywords):
                detected_emotions.append(emotion)
        
        return detected_emotions[:3]  # M√°ximo 3 emo√ß√µes principais
    
    def _identify_risk_indicators(self, text: str) -> List[str]:
        """Identifica indicadores de risco no texto"""
        risk_keywords = {
            'suicidal_ideation': ['suic√≠dio', 'acabar com tudo', 'n√£o aguento mais', 'quero morrer'],
            'self_harm': ['me machucar', 'me cortar', 'autoles√£o', 'me ferir'],
            'substance_abuse': ['bebendo muito', 'usando drogas', 'viciado', 'dependente'],
            'eating_disorder': ['n√£o como', 'vomito', 'bulimia', 'anorexia'],
            'severe_depression': ['n√£o vejo sentido', 'vida sem prop√≥sito', 'desesperan√ßa total'],
            'panic_attacks': ['p√¢nico', 'cora√ß√£o acelerado', 'n√£o consigo respirar', 'ataque'],
            'social_isolation': ['n√£o saio', 'evito pessoas', 'me isolo', 'ningu√©m me entende']
        }
        
        text_lower = text.lower()
        risk_indicators = []
        
        for risk_type, keywords in risk_keywords.items():
            if any(keyword in text_lower for keyword in keywords):
                risk_indicators.append(risk_type)
        
        return risk_indicators
    
    def _extract_themes(self, text: str) -> List[str]:
        """Extrai temas principais do texto"""
        theme_keywords = {
            'trabalho': ['trabalho', 'emprego', 'chefe', 'colega', 'carreira', 'profissional'],
            'fam√≠lia': ['fam√≠lia', 'pai', 'm√£e', 'irm√£o', 'filho', 'parente'],
            'relacionamento': ['namorado', 'namorada', 'marido', 'esposa', 'relacionamento', 'amor'],
            'estudos': ['escola', 'universidade', 'faculdade', 'estudo', 'prova', 'professor'],
            'sa√∫de': ['sa√∫de', 'doen√ßa', 'm√©dico', 'hospital', 'tratamento', 'dor'],
            'finan√ßas': ['dinheiro', 'financeiro', 'conta', 'pagamento', 'd√≠vida', 'sal√°rio'],
            'amizade': ['amigo', 'amiga', 'amizade', 'colega', 'turma'],
            'futuro': ['futuro', 'planos', 'objetivos', 'sonhos', 'metas', 'amanh√£'],
            'autoestima': ['autoestima', 'confian√ßa', 'inseguro', 'valor pr√≥prio', 'autoimagem']
        }
        
        text_lower = text.lower()
        themes = []
        
        for theme, keywords in theme_keywords.items():
            keyword_count = sum(1 for keyword in keywords if keyword in text_lower)
            if keyword_count >= 2:  # Pelo menos 2 palavras-chave do tema
                themes.append(theme)
            elif keyword_count == 1 and len([k for k in keywords if k in text_lower and len(k) > 6]) > 0:
                # Uma palavra-chave espec√≠fica/longa
                themes.append(theme)
        
        return themes[:5]  # M√°ximo 5 temas
    
    def generate_response(self, user_message: str, risk_level: str = 'low', 
                         user_context: Optional[Dict] = None, 
                         conversation_history: Optional[List] = None, 
                         fallback: bool = True) -> Dict:
        """
        Gera resposta emp√°tica usando LLMs com RAG avan√ßado e Prompt Engineering
        
        Args:
            user_message: Mensagem do usu√°rio
            risk_level: N√≠vel de risco detectado
            user_context: Contexto do usu√°rio (nome, etc.)
            conversation_history: Hist√≥rico da conversa
            fallback: Se deve usar fallback em caso de erro
            
        Returns:
            Dict com resposta gerada e metadados
        """
        errors = []

        # RESPOSTAS INTELIGENTES SOBRE O HIST√ìRICO E CONTEXTO COMPLETO
        user_message_lower = user_message.lower()


        errors = []
        
        try:
            print(f"AI_RESPONSE_START: Processando mensagem de risco {risk_level}")
            
            # 1. Buscar contexto avan√ßado usando RAG
            rag_context = None
            rag_result = None
            if self.rag_enabled:
                try:
                    rag_result = self.rag.get_enhanced_context(
                        user_message, 
                        risk_level, 
                        context_type='all', 
                        limit=3
                    )
                    rag_context = rag_result.get('context_prompt', '')
                    print(f"RAG_CONTEXT: {len(rag_result.get('training_data', []))} dados + {len(rag_result.get('conversation_examples', []))} conversas")
                except Exception as e:
                    logger.warning(f"Erro no RAG: {e}")

            # 2. Preparar contexto para prompt engineering (incluindo triagem)
            prompt_context = PromptContext(
                user_message=user_message,
                risk_level=RiskLevel(risk_level),
                user_name=user_context.get('name') if user_context else None,
                session_history=conversation_history,
                training_context=rag_context,
                conversation_examples=rag_result.get('conversation_examples', []) if rag_result else None
            )


            # 2.1. Adicionar contexto de triagem se dispon√≠vel
            if user_context:
                triage_triggered = user_context.get('triage_triggered', False)
                triage_status = user_context.get('triage_status')
                triage_declined_reason = user_context.get('triage_declined_reason')

                # Construir contexto de triagem para a IA
                triage_context_info = ""
                triage_print_reason = None
                if triage_triggered:
                    if triage_status == 'declined':
                        triage_context_info = f"\n\nCONTEXTO IMPORTANTE: O usu√°rio recusou participar da triagem psicol√≥gica. "
                        if triage_declined_reason:
                            triage_context_info += f"Motivo: {triage_declined_reason}. "
                            triage_print_reason = f"Usu√°rio recusou triagem. Motivo: {triage_declined_reason}"
                        else:
                            triage_print_reason = "Usu√°rio recusou triagem. Sem motivo informado."
                        triage_context_info += "Seja respeitoso com essa decis√£o, mas mantenha-se atento aos sinais de risco. N√£o insista na triagem, mas continue oferecendo apoio emocional."
                    elif triage_status == 'initiated':
                        triage_context_info = f"\n\nCONTEXTO: O usu√°rio iniciou o processo de triagem psicol√≥gica. Apoie e encoraje a continuidade deste processo."
                        triage_print_reason = "Usu√°rio iniciou a triagem psicol√≥gica."
                    elif triage_status == 'completed':
                        triage_context_info = f"\n\nCONTEXTO: O usu√°rio completou a triagem psicol√≥gica. Use essas informa√ß√µes para personalizar melhor suas respostas."
                        triage_print_reason = "Usu√°rio completou a triagem psicol√≥gica."

                # Adicionar ao contexto de treinamento
                if triage_context_info and prompt_context.training_context:
                    prompt_context.training_context += triage_context_info
                elif triage_context_info:
                    prompt_context.training_context = triage_context_info

                # Print informativo
                if triage_print_reason:
                    print(f"[TRIAGEM ATIVADA] Status: {triage_status} | Motivo: {triage_print_reason}")

            # 3. Tentar OpenAI consolidado
            if self.openai_client:
                try:
                    prompt_data = self.prompt_manager.build_contextual_prompt(prompt_context, provider='openai')
                    response = self.openai_client.chat.completions.create(
                        model=self.openai_model,
                        messages=prompt_data['messages'],
                        max_tokens=prompt_data.get('max_tokens', 120),
                        temperature=prompt_data.get('temperature', 0.7),
                        presence_penalty=prompt_data.get('presence_penalty', 0),
                        frequency_penalty=prompt_data.get('frequency_penalty', 0)
                    )
                    ai_response = response.choices[0].message.content.strip()
                    result = {
                        'message': ai_response,
                        'risk_level': prompt_context.risk_level.value,
                        'confidence': 0.95,
                        'source': 'openai',
                        'model': self.openai_model,
                        'rag_used': bool(prompt_context.training_context),
                        'prompt_engineering': 'consolidated',
                        'timestamp': datetime.now(UTC).isoformat(),
                        'tokens_used': response.usage.total_tokens if hasattr(response, 'usage') else None
                    }
                    if prompt_context.training_context:
                        result['rag_context_length'] = len(prompt_context.training_context)
                    return result
                except Exception as e:
                    errors.append(f"OpenAI: {str(e)}")
                    logger.warning(f"Falha no OpenAI: {e}")

            # 4. Tentar Gemini consolidado (fallback)
            if self.gemini_client and fallback:
                try:
                    prompt_data = self.prompt_manager.build_contextual_prompt(prompt_context, provider='gemini')
                    model = self.gemini_client.GenerativeModel(self.gemini_model)
                    response = model.generate_content(prompt_data['prompt'])
                    ai_response = response.text.strip()
                    result = {
                        'message': ai_response,
                        'risk_level': prompt_context.risk_level.value,
                        'confidence': 0.90,
                        'source': 'gemini',
                        'rag_used': bool(prompt_context.training_context),
                        'prompt_engineering': 'consolidated',
                        'timestamp': datetime.now(UTC).isoformat()
                    }
                    if prompt_context.training_context:
                        result['rag_context_length'] = len(prompt_context.training_context)
                    return result
                except Exception as e:
                    errors.append(f"Gemini: {str(e)}")
                    logger.warning(f"Falha no Gemini: {e}")

            # 5. Fallback para resposta est√°tica
            return self._generate_response_fallback(user_message, risk_level, user_context, errors)
            
        except Exception as e:
            logger.error(f"Erro cr√≠tico na gera√ß√£o de resposta: {e}")
            return self._generate_response_fallback(user_message, risk_level, user_context, errors + [str(e)])
    
    
    def _generate_response_fallback(self, user_message: str, risk_level: str, 
                                   user_context: Optional[Dict], 
                                   errors: Optional[List] = None) -> Dict:
        """Gera resposta est√°tica como fallback final"""
        
        # Obter respostas do sistema de prompts
        responses = self.prompt_manager.get_fallback_responses(risk_level, user_context)
        message = random.choice(responses)
        
        return {
            'message': message,
            'risk_level': risk_level,
            'confidence': 0.3,
            'source': 'fallback',
            'errors': errors or [],
            'timestamp': datetime.now(UTC).isoformat()
        }
    
    def _cache_result(self, key: str, result: Dict) -> None:
        """Gerencia cache com limpeza autom√°tica"""
        try:
            if len(self.response_cache) >= self.cache_max_size:
                # Remove primeiros 20% dos itens
                items_to_remove = list(self.response_cache.keys())[:self.cache_max_size // 5]
                for item_key in items_to_remove:
                    del self.response_cache[item_key]
            
            self.response_cache[key] = result
        except Exception as e:
            logger.warning(f"Erro ao cachear: {e}")
    
    def get_model_info(self) -> List[Dict]:
        """Retorna informa√ß√µes sobre modelos configurados"""
        return [
            {
                'provider': 'OpenAI',
                'model': self.openai_model,
                'status': 'active' if self.openai_client else 'inactive',
                'type': 'cloud',
                'primary': True
            },
            {
                'provider': 'Gemini',
                'model': self.gemini_model,
                'status': 'active' if self.gemini_client else 'inactive',
                'type': 'cloud',
                'primary': False
            },
            {
                'provider': 'RAG',
                'model': 'SimpleRAG',
                'status': 'active' if self.rag_enabled else 'inactive',
                'type': 'enhancement',
                'primary': False
            },
            {
                'provider': 'PromptManager',
                'model': 'AIPromptManager',
                'status': 'active',
                'type': 'prompt_system',
                'primary': False
            },
            {
                'provider': 'Fallback',
                'model': 'static_responses',
                'status': 'always',
                'type': 'static',
                'primary': False
            }
        ]
    
    def get_service_statistics(self) -> Dict:
        """Retorna estat√≠sticas do servi√ßo"""
        try:
            stats = {
                'service_version': '3.0',
                'architecture': 'advanced_integrated_system',
                'models_active': len([m for m in self.get_model_info() if m['status'] == 'active']),
                'cache_size': len(self.response_cache),
                'rag_enabled': self.rag_enabled,
                'prompt_manager_active': bool(self.prompt_manager),
                'training_logging_enabled': self.log_training_usage,
                'advanced_systems': {
                    'advanced_rag': bool(self.advanced_rag),
                    'consolidated_prompt_manager': bool(self.prompt_manager),
                    'finetuning_preparator': bool(self.finetuning_preparator)
                }
            }
            
            # Estat√≠sticas do RAG avan√ßado
            if self.advanced_rag:
                try:
                    rag_stats = self.advanced_rag.get_training_data_statistics()
                    stats['advanced_rag_stats'] = rag_stats
                except Exception as e:
                    stats['advanced_rag_error'] = str(e)
            
            # Estat√≠sticas do sistema consolidado de prompts
            if self.prompt_manager:
                try:
                    prompt_stats = self.prompt_manager.get_prompt_statistics()
                    stats['prompt_engineering_stats'] = prompt_stats
                except Exception as e:
                    stats['prompt_engineering_error'] = str(e)
            
            # Estat√≠sticas do fine-tuning
            if self.finetuning_preparator:
                try:
                    ft_recommendations = self.finetuning_preparator.get_dataset_recommendations()
                    stats['finetuning_recommendations'] = ft_recommendations
                except Exception as e:
                    stats['finetuning_error'] = str(e)
            
            # Estat√≠sticas de uso de treinamento
            if self.log_training_usage:
                stats['training_usage_error'] = 'Training logger n√£o dispon√≠vel'
            
            return stats
        except Exception as e:
            return {'error': str(e)}
    
    def search_training_content(self, query: str, limit: int = 10) -> Dict:
        """
        Busca conte√∫do nos dados de treinamento
        """
        try:
            if not self.advanced_rag:
                return {'error': 'Sistema RAG avan√ßado n√£o dispon√≠vel'}
            
            results = self.advanced_rag.search_training_content(query, limit)
            
            return {
                'success': True,
                'query': query,
                'results': results,
                'total_found': len(results)
            }
            
        except Exception as e:
            logger.error(f"Erro na busca de conte√∫do: {e}")
            return {'error': str(e)}
    
    def create_finetuning_dataset(self, dataset_type: str = 'hybrid', 
                                 format_type: str = 'openai_chat',
                                 max_samples: int = 1000) -> Dict:
        """
        Cria dataset para fine-tuning
        
        Args:
            dataset_type: Tipo do dataset ('conversations', 'training_data', 'hybrid')
            format_type: Formato ('openai_chat', 'jsonl', 'csv')
            max_samples: N√∫mero m√°ximo de amostras
        """
        try:
            if not self.finetuning_preparator:
                return {'error': 'Preparador de fine-tuning n√£o dispon√≠vel'}
            
            print(f"FINETUNING_DATASET: Criando dataset {dataset_type} formato {format_type}")
            
            if dataset_type == 'conversations':
                result = self.finetuning_preparator.create_conversation_dataset(
                    format_type=format_type,
                    max_samples=max_samples
                )
            elif dataset_type == 'training_data':
                result = self.finetuning_preparator.create_training_data_dataset(
                    format_type=format_type,
                    max_samples=max_samples
                )
            elif dataset_type == 'hybrid':
                result = self.finetuning_preparator.create_hybrid_dataset(
                    total_samples=max_samples,
                    format_type=format_type
                )
            else:
                return {'error': f'Tipo de dataset n√£o suportado: {dataset_type}'}
            
            return result
            
        except Exception as e:
            logger.error(f"Erro na cria√ß√£o do dataset: {e}")
            return {'error': str(e)}
    
    def save_finetuning_dataset(self, dataset_result: Dict, file_path: str = None) -> Dict:
        """
        Salva dataset de fine-tuning em arquivo
        """
        try:
            if not self.finetuning_preparator:
                return {'error': 'Preparador de fine-tuning n√£o dispon√≠vel'}
            
            return self.finetuning_preparator.save_dataset_to_file(dataset_result, file_path)
            
        except Exception as e:
            logger.error(f"Erro ao salvar dataset: {e}")
            return {'error': str(e)}
    
    def get_advanced_context(self, user_message: str, risk_level: str = 'low',
                           context_type: str = 'all') -> Dict:
        """
        Obt√©m contexto avan√ßado usando RAG
        """
        try:
            if not self.advanced_rag:
                return {'error': 'Sistema RAG avan√ßado n√£o dispon√≠vel'}
            
            return self.advanced_rag.get_enhanced_context(
                user_message, risk_level, context_type
            )
            
        except Exception as e:
            logger.error(f"Erro no contexto avan√ßado: {e}")
            return {'error': str(e)}
    
    def analyze_prompt_context(self, user_message: str, risk_level: str = 'low',
                             user_context: Optional[Dict] = None) -> Dict:
        """
        Analisa contexto para prompt engineering
        """
        try:
            if not self.prompt_manager:
                return {'error': 'Sistema de prompt engineering n√£o dispon√≠vel'}
            
            # PromptContext, RiskLevel j√° importados no topo
            
            # Criar contexto
            prompt_context = PromptContext(
                user_message=user_message,
                risk_level=RiskLevel(risk_level),
                user_name=user_context.get('name') if user_context else None
            )
            
            # Validar contexto
            is_valid, errors = self.prompt_manager.validate_prompt_context(prompt_context)
            
            # Construir prompt de exemplo
            prompt_data = self.prompt_manager.build_contextual_prompt(
                prompt_context, provider='openai'
            )
            
            return {
                'success': True,
                'context_valid': is_valid,
                'validation_errors': errors,
                'prompt_preview': {
                    'system_message': prompt_data['messages'][0]['content'][:500] + '...',
                    'user_message': prompt_data['messages'][-1]['content'],
                    'total_messages': len(prompt_data['messages']),
                    'max_tokens': prompt_data['max_tokens'],
                    'temperature': prompt_data['temperature']
                }
            }
            
        except Exception as e:
            logger.error(f"Erro na an√°lise do prompt: {e}")
            return {'error': str(e)}
    
    def get_system_capabilities(self) -> Dict:
        """
        Retorna capacidades completas do sistema
        """
        return {
            'core_features': {
                'sentiment_analysis': True,
                'risk_assessment': True,
                'response_generation': True,
                'diary_analysis': True
            },
            'advanced_features': {
                'advanced_rag': bool(self.advanced_rag),
                'consolidated_prompt_engineering': bool(self.prompt_manager),
                'finetuning_preparation': bool(self.finetuning_preparator),
                'training_usage_logging': self.log_training_usage
            },
            'supported_formats': {
                'finetuning': ['openai_chat', 'openai_completion', 'jsonl', 'csv'],
                'rag_context': ['training_data', 'conversa√ß√µes', 'hybrid']
            },
            'models': self.get_model_info(),
            'version': '3.0 - Integrated Advanced System'
        }
    
    def get_training_usage_report(self) -> Dict:
        """
        Retorna relat√≥rio detalhado do uso de dados de treinamento
        """
        return {'error': 'Training logger n√£o est√° dispon√≠vel'}
    
    def clear_training_cache(self) -> Dict:
        """
        Limpa o cache de dados de treinamento
        """
        return {'error': 'Training logger n√£o est√° dispon√≠vel'}


# === FUN√á√ïES DE CONVENI√äNCIA ===

def create_ai_service(app=None) -> AIService:
    """Cria inst√¢ncia configurada do AIService"""
    return AIService(app)

# Alias para compatibilidade
EmotionalSupportAgent = AIService


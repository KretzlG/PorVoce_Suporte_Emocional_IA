"""
Sistema de Prompts Profissional para IA de Suporte Emocional
Centraliza todos os prompts, instru√ß√µes e configura√ß√µes de tom

"""

from typing import Dict, Optional, List
from datetime import datetime


class AIPromptManager:
    """
    Gerenciador Central de Prompts para Suporte Emocional
    
    Funcionalidades:
    - Prompts personalizados por n√≠vel de risco
    - Instru√ß√µes espec√≠ficas para primeira conversa vs continua√ß√£o
    - Templates de sistema para an√°lise de sentimento
    - Configura√ß√µes de tom e comportamento
    - Prompts para diferentes providers (OpenAI, Gemini, etc.)
    """
    
    def __init__(self):
        """Inicializa o gerenciador com todos os prompts organizados"""
        
        # === PROMPTS PARA AN√ÅLISE DE SENTIMENTO ===
        self.sentiment_analysis_prompts = {
            'openai_system': (
                "Voc√™ √© um especialista em an√°lise de sentimento emocional em portugu√™s brasileiro.\n"
                "Analise o texto e retorne APENAS um JSON v√°lido:\n"
                "{\n"
                '  "score": n√∫mero entre -1 (muito negativo) e 1 (muito positivo),\n'
                '  "confidence": n√∫mero entre 0 e 1,\n'
                '  "emotion": "feliz|triste|ansioso|irritado|desesperado|vazio|neutro|esperan√ßoso|calmo",\n'
                '  "intensity": "low|moderate|high"\n'
                "}\n\n"
                "IMPORTANTE:\n"
                "- Seja preciso na an√°lise emocional\n"
                "- Considere contexto cultural brasileiro\n" 
                "- Detecte sutilezas e entrelinhas\n"
                "- Priorize seguran√ßa em casos amb√≠guos"
            ),
            
            'gemini_system': (
                "Analise o sentimento emocional deste texto em portugu√™s brasileiro.\n"
                "Retorne um JSON com:\n"
                "- score: -1 a 1 (negativo/positivo)\n"
                "- confidence: 0 a 1\n"
                "- emotion: feliz, triste, ansioso, irritado, desesperado, vazio, neutro, esperan√ßoso, calmo\n"
                "- intensity: low, moderate, high\n"
                "Seja preciso e considere o contexto cultural brasileiro."
            )
        }
        
        # === INSTRU√á√ïES DE TOM POR N√çVEL DE RISCO ===
        self.tone_instructions = {
            'low': {
                'primary': "Seja otimista, encorajadora e energ√©tica.",
                'details': "Use energia positiva, foque em solu√ß√µes e for√ßas da pessoa."
            },
            'moderate': {
                'primary': "Seja compreensiva mas firme e esperan√ßosa.",
                'details': "Valide sentimentos, mas direcione para a√ß√£o e crescimento."
            },
            'high': {
                'primary': "Seja carinhosa mas direta sobre buscar ajuda.",
                'details': "Transmita urg√™ncia com esperan√ßa, foque na solu√ß√£o imediata."
            },
            'critical': {
                'primary': "Seja firme, direta e protetiva. Priorize a√ß√£o IMEDIATA.",
                'details': "Seguran√ßa em primeiro lugar. Seja clara sobre necessidade de ajuda profissional AGORA."
            }
        }
        
        # === PROMPTS BASE PARA DIFERENTES SITUA√á√ïES ===
        self.base_prompts = {
            'first_interaction': {
                'openai': self._get_first_interaction_prompt_openai(),
                'gemini': self._get_first_interaction_prompt_gemini()
            },
            'continuation': {
                'openai': self._get_continuation_prompt_openai(),
                'gemini': self._get_continuation_prompt_gemini()
            }
        }
        
        # === PROMPTS DE EMERG√äNCIA ===
        self.emergency_prompts = self._get_emergency_prompts()
        
        # === CONFIGURA√á√ïES DE PAR√ÇMETROS ===
        self.response_parameters = {
            'first_interaction_max_words': 40,
            'continuation_max_words': 50,
            'emergency_max_words': 60,
            'temperature_empathetic': 0.8,
            'temperature_analytical': 0.3
        }
    
    def get_sentiment_prompt(self, provider: str = 'openai') -> str:
        """
        Retorna prompt para an√°lise de sentimento
        
        Args:
            provider: 'openai' ou 'gemini'
            
        Returns:
            String com prompt formatado para an√°lise de sentimento
        """
        return self.sentiment_analysis_prompts.get(f'{provider}_system', 
                                                  self.sentiment_analysis_prompts['openai_system'])
    
    def build_conversation_prompt(self, 
                                user_message: str,
                                risk_level: str,
                                provider: str = 'openai',
                                user_context: Optional[Dict] = None,
                                conversation_history: Optional[List] = None,
                                rag_context: Optional[str] = None,
                                is_first_message: bool = False) -> Dict:
        """
        Constr√≥i prompt completo para gera√ß√£o de resposta
        
        Args:
            user_message: Mensagem do usu√°rio
            risk_level: N√≠vel de risco detectado
            provider: Provider de IA ('openai', 'gemini')
            user_context: Contexto do usu√°rio
            conversation_history: Hist√≥rico da conversa
            rag_context: Contexto do sistema RAG
            is_first_message: Se √© primeira intera√ß√£o
            
        Returns:
            Dict com prompt estruturado e metadados
        """
        # Extrair nome do usu√°rio
        user_name = ""
        if user_context and user_context.get('name'):
            user_name = user_context['name'].split()[0]
        
        # An√°lise din√¢mica da conversa
        conversation_mood = self._analyze_conversation_mood(conversation_history)
        adaptation_rules = self._get_adaptation_rules(conversation_mood, risk_level)
        
        # Selecionar template base
        template_type = 'first_interaction' if is_first_message else 'continuation'
        base_template = self.base_prompts[template_type][provider]
        
        # Construir prompt do sistema
        system_prompt = base_template.format(
            risk_level=risk_level.upper(),
            tone_instruction=self.tone_instructions[risk_level]['primary'],
            tone_details=self.tone_instructions[risk_level]['details'],
            user_name_instruction=f"Use {user_name}" if user_name else "",
            max_words=self.response_parameters[f'{template_type}_max_words']
        )
        
        # Adicionar adapta√ß√µes din√¢micas
        if adaptation_rules:
            system_prompt += f"\n\nADAPTA√á√ÉO NECESS√ÅRIA: {adaptation_rules}"
        
        # Adicionar contexto RAG se dispon√≠vel
        if rag_context:
            system_prompt += f"\n\n{rag_context}"
        
        # Adicionar instru√ß√µes de emerg√™ncia para risco cr√≠tico
        if risk_level == 'critical':
            system_prompt += self.emergency_prompts['critical_instructions']
        
        # Construir estrutura de mensagens
        if provider == 'openai':
            messages = [{"role": "system", "content": system_prompt}]
            
            # Adicionar hist√≥rico limitado (√∫ltimas 4 mensagens para manter foco)
            if conversation_history:
                recent_history = conversation_history[-4:]
                for msg in recent_history:
                    role = "user" if msg.get('message_type') == 'USER' else "assistant"
                    messages.append({"role": role, "content": msg.get('content', '')})
            
            # Mensagem atual
            messages.append({"role": "user", "content": user_message})
            
            return {
                'messages': messages,
                'temperature': self.response_parameters['temperature_empathetic'],
                'max_tokens': self._calculate_max_tokens(template_type, risk_level)
            }
        
        elif provider == 'gemini':
            # Gemini usa prompt √∫nico
            full_prompt = f"{system_prompt}\n\nMensagem do usu√°rio: {user_message}"
            
            return {
                'prompt': full_prompt,
                'temperature': self.response_parameters['temperature_empathetic']
            }
        
        else:
            raise ValueError(f"Provider '{provider}' n√£o suportado")
    
    def get_fallback_responses(self, risk_level: str, user_context: Optional[Dict] = None) -> List[str]:
        """
        Retorna respostas est√°ticas organizadas por n√≠vel de risco
        
        Args:
            risk_level: N√≠vel de risco detectado
            user_context: Contexto do usu√°rio para personaliza√ß√£o
            
        Returns:
            Lista de poss√≠veis respostas est√°ticas
        """
        user_name = ""
        if user_context and user_context.get('name'):
            user_name = user_context['name'].split()[0]
            name_prefix = f"{user_name}, " if user_name else ""
        else:
            name_prefix = ""
        
        fallback_responses = {
            'critical': [
                f"{name_prefix}SITUA√á√ÉO CR√çTICA DETECTADA! "
                "Nossa equipe especializada foi acionada para te apoiar. üö®",
                
                f"{name_prefix}TRIAGEM EMERGENCIAL ATIVADA! "
                "Um profissional entrar√° em contato imediatamente. ‚ö†Ô∏è",
                
                f"{name_prefix}VOC√ä N√ÉO EST√Å SOZINHO! "
                "Nossa equipe de crise est√° organizando seu atendimento AGORA. üÜò"
            ],
            
            'high': [
                f"{name_prefix}nossa triagem especializada ir√° te atender. "
                "Voc√™ merece todo o suporte que podemos oferecer! üí™",
                
                f"{name_prefix}conectando voc√™ com nossa equipe de profissionais. "
                "Juntos vamos encontrar solu√ß√µes. Voc√™ tem for√ßa! üåü",
                
                f"{name_prefix}acionando protocolo de apoio intensivo. "
                "Nossa plataforma est√° aqui para voc√™. Dias melhores v√£o chegar! ‚òÄÔ∏è"
            ],
            
            'moderate': [
                f"{name_prefix}nossa equipe pode te oferecer suporte mais direcionado! "
                "O que voc√™ pode fazer hoje para se cuidar melhor? üí≠",
                
                f"{name_prefix}voc√™ √© mais forte do que imagina. "
                "Vamos conectar voc√™ com recursos internos que podem ajudar? üåü",
                
                f"{name_prefix}isso vai passar! Nossa triagem pode organizar "
                "um acompanhamento personalizado para voc√™. ‚ú®"
            ],
            
            'low': [
                f"{name_prefix}que bom ter voc√™ aqui! "
                "Conte-me como posso te apoiar hoje. üòä",
                
                f"{name_prefix}oi! Como voc√™ est√° se sentindo agora? üíö",
                
                f"{name_prefix}estou aqui para te ouvir! "
                "O que est√° acontecendo? üó£Ô∏è"
            ]
        }
        
        return fallback_responses.get(risk_level, fallback_responses['low'])
    
    def _get_first_interaction_prompt_openai(self) -> str:
        """Template para primeira intera√ß√£o - OpenAI"""
        return """Voc√™ √© √çris, assistente de apoio emocional brasileira.

PRIMEIRA CONVERSA | RISCO: {risk_level}
{tone_instruction} {tone_details}

REGRAS R√çGIDAS:
- NUNCA se apresente ap√≥s a primeira frase
- NUNCA pe√ßa desculpas desnecessariamente  
- NUNCA diga "entendo que", "sei que √© dif√≠cil"
- FOQUE na pessoa, n√£o em voc√™
- Seja DIRETA e PR√ÅTICA
- Use energia POSITIVA sempre que poss√≠vel
{user_name_instruction}

M√ÅXIMO {max_words} palavras. Seja concisa e eficaz."""
    
    def _get_continuation_prompt_openai(self) -> str:
        """Template para continua√ß√£o de conversa - OpenAI"""
        return """Continue como √çris em conversa em andamento.

CONVERSA CONTINUADA | RISCO: {risk_level}
{tone_instruction} {tone_details}

REGRAS OBRIGAT√ìRIAS:
- NUNCA se apresente novamente
- NUNCA repita frases como "estou aqui para", "sinto muito"
- Responda DIRETAMENTE ao que foi dito
- Adapte seu tom ao ESTADO EMOCIONAL atual
- Seja PR√ÅTICA e SOLUCIONADORA
- Use ENERGIA para motivar
{user_name_instruction}

M√ÅXIMO {max_words} palavras. V√° direto ao ponto."""
    
    def _get_first_interaction_prompt_gemini(self) -> str:
        """Template para primeira intera√ß√£o - Gemini"""
        return """Voc√™ √© √çris, IA de apoio emocional em portugu√™s brasileiro.

PRIMEIRA conversa. RISCO: {risk_level}
{tone_instruction} {tone_details}

Apresente-se brevemente e seja acolhedora.
{user_name_instruction}
M√°ximo {max_words} palavras."""
    
    def _get_continuation_prompt_gemini(self) -> str:
        """Template para continua√ß√£o - Gemini"""
        return """Voc√™ √© √çris, continuando conversa de apoio emocional.

RISCO: {risk_level}
{tone_instruction} {tone_details}

Continue naturalmente, sem se apresentar.
{user_name_instruction}
M√°ximo {max_words} palavras."""
    
    def _get_emergency_prompts(self) -> Dict:
        """Prompts espec√≠ficos para situa√ß√µes de emerg√™ncia"""
        return {
            'critical_instructions': """

‚ö†Ô∏è SITUA√á√ÉO DE RISCO CR√çTICO DETECTADA:
- Enfatize urg√™ncia de ajuda IMEDIATA
- Ative triagem emergencial interna
- Sugira procurar hospital/pronto-socorro
- Seja firme mas emp√°tico
- N√ÉO minimize a situa√ß√£o
- Priorize seguran√ßa acima de tudo""",
            
            'crisis_contacts': {
                'triagem_interna': "Triagem Especializada - Equipe interna dispon√≠vel 24h",
                'samu': "SAMU: 192 (emerg√™ncias m√©dicas)",
                'emergency': "Em emerg√™ncia: v√° ao hospital mais pr√≥ximo"
            }
        }
    
    def _calculate_max_tokens(self, template_type: str, risk_level: str) -> int:
        """Calcula n√∫mero m√°ximo de tokens baseado no contexto"""
        base_tokens = {
            'first_interaction': 80,
            'continuation': 100
        }
        
        # Aumentar tokens apenas para situa√ß√µes cr√≠ticas
        if risk_level == 'critical':
            return base_tokens.get(template_type, 100) + 30
        elif risk_level == 'high':
            return base_tokens.get(template_type, 100) + 20
        else:
            return base_tokens.get(template_type, 100)
    
    def get_provider_config(self, provider: str) -> Dict:
        """
        Retorna configura√ß√µes espec√≠ficas por provider
        
        Args:
            provider: Nome do provider ('openai', 'gemini')
            
        Returns:
            Dict com configura√ß√µes do provider
        """
        configs = {
            'openai': {
                'supports_system_message': True,
                'supports_conversation_history': True,
                'max_context_messages': 6,
                'preferred_temperature': 0.7,
                'supports_json_mode': True
            },
            'gemini': {
                'supports_system_message': False,
                'supports_conversation_history': False,
                'max_context_messages': 0,
                'preferred_temperature': 0.7,
                'supports_json_mode': False
            }
        }
        
        return configs.get(provider, configs['openai'])
    
    def _analyze_conversation_mood(self, conversation_history: Optional[List]) -> str:
        """
        Analisa o humor geral da conversa para adapta√ß√£o din√¢mica
        
        Args:
            conversation_history: Hist√≥rico das mensagens
            
        Returns:
            String indicando o humor: 'improving', 'worsening', 'stable', 'crisis', 'unknown'
        """
        if not conversation_history or len(conversation_history) < 3:
            return 'unknown'
        
        try:
            # Analisa as √∫ltimas 4 mensagens do usu√°rio
            user_messages = [
                msg for msg in conversation_history[-6:] 
                if msg.get('message_type') == 'USER'
            ][-4:]
            
            if len(user_messages) < 2:
                return 'unknown'
            
            # Palavras que indicam melhora
            improvement_words = [
                'melhor', 'melhorando', 'obrigado', 'ajudou', 'consegui', 
                'tentando', 'for√ßa', 'esperan√ßa', 'positivo', 'bem'
            ]
            
            # Palavras que indicam piora
            worsening_words = [
                'pior', 'piorando', 'desistir', 'acabou', 'imposs√≠vel', 
                'n√£o aguento', 'sem sa√≠da', 'desespero', 'vazio'
            ]
            
            # Palavras de crise
            crisis_words = [
                'morrer', 'suic√≠dio', 'acabar com tudo', 'n√£o quero viver',
                'me matar', 'melhor morto'
            ]
            
            improvement_score = 0
            worsening_score = 0
            crisis_score = 0
            
            for msg in user_messages:
                content = msg.get('content', '').lower()
                
                improvement_score += sum(1 for word in improvement_words if word in content)
                worsening_score += sum(1 for word in worsening_words if word in content)
                crisis_score += sum(1 for word in crisis_words if word in content)
            
            # Determinar humor
            if crisis_score > 0:
                return 'crisis'
            elif improvement_score > worsening_score:
                return 'improving'
            elif worsening_score > improvement_score:
                return 'worsening'
            else:
                return 'stable'
                
        except Exception:
            return 'unknown'
    
    def _get_adaptation_rules(self, conversation_mood: str, risk_level: str) -> str:
        """
        Retorna regras de adapta√ß√£o baseadas no humor da conversa
        
        Args:
            conversation_mood: Humor detectado da conversa
            risk_level: N√≠vel de risco atual
            
        Returns:
            String com regras espec√≠ficas de adapta√ß√£o
        """
        adaptations = {
            'improving': "Pessoa est√° melhorando! Reforce progresso, seja AINDA MAIS POSITIVA e encorajadora. Celebre pequenas vit√≥rias!",
            
            'worsening': "Situa√ß√£o piorando. Seja mais FIRME e DIRETA sobre buscar ajuda. Aumente energia positiva para contrabalan√ßar.",
            
            'crisis': "CRISE DETECTADA. Seja EXTREMAMENTE DIRETA sobre buscar ajuda IMEDIATA. Priorize seguran√ßa acima de tudo.",
            
            'stable': "Conversa est√°vel. Mantenha tom consistente e foque em pequenos passos para frente.",
            
            'unknown': "Primeira conversa ou dados insuficientes. Seja calorosa mas n√£o excessiva."
        }
        
        adaptation = adaptations.get(conversation_mood, '')
        
        # Ajustes espec√≠ficos por risco
        if risk_level == 'critical' and conversation_mood != 'improving':
            adaptation += " REFORCE urg√™ncia de ajuda profissional."
        elif risk_level == 'low' and conversation_mood == 'improving':
            adaptation += " Use mais humor e leveza."
            
        return adaptation
    
    def validate_prompt_length(self, prompt: str, provider: str) -> bool:
        """
        Valida se o prompt est√° dentro dos limites do provider
        
        Args:
            prompt: Texto do prompt
            provider: Nome do provider
            
        Returns:
            True se v√°lido, False caso contr√°rio
        """
        limits = {
            'openai': 8000,  # Aproximadamente para gpt-4o-mini
            'gemini': 6000   # Aproximadamente para gemini-pro
        }
        
        # Estimativa simples: 4 caracteres por token
        estimated_tokens = len(prompt) // 4
        
        return estimated_tokens <= limits.get(provider, 8000)


# === FUN√á√ïES DE CONVENI√äNCIA ===

def create_prompt_manager() -> AIPromptManager:
    """Cria inst√¢ncia configurada do AIPromptManager"""
    return AIPromptManager()

# Inst√¢ncia global para uso direto
prompt_manager = AIPromptManager()

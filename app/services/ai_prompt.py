"""
Sistema de Prompts Profissional para IA de Suporte Emocional
Centraliza todos os prompts, instru√ß√µes e configura√ß√µes de tom

"""

from typing import Dict, Optional, List
from datetime import datetime


class AIPromptManager:
    """
    Gerenciador Central de Prompts para Suporte Emocional
    
    Funcionalidades:
    - Prompts personalizados por n√≠vel de risco
    - Instru√ß√µes espec√≠ficas para primeira conversa vs continua√ß√£o
    - Templates de sistema para an√°lise de sentimento
    - Configura√ß√µes de tom e comportamento
    - Prompts para diferentes providers (OpenAI, Gemini, etc.)
    """
    
    def __init__(self):
        """Inicializa o gerenciador com todos os prompts organizados"""
        
        # === PROMPTS PARA AN√ÅLISE DE SENTIMENTO ===
        self.sentiment_analysis_prompts = {
            'openai_system': (
                "Voc√™ √© um especialista em an√°lise de sentimento emocional em portugu√™s brasileiro.\n"
                "Analise o texto e retorne APENAS um JSON v√°lido:\n"
                "{\n"
                '  "score": n√∫mero entre -1 (muito negativo) e 1 (muito positivo),\n'
                '  "confidence": n√∫mero entre 0 e 1,\n'
                '  "emotion": "feliz|triste|ansioso|irritado|desesperado|vazio|neutro|esperan√ßoso|calmo",\n'
                '  "intensity": "low|moderate|high"\n'
                "}\n\n"
                "IMPORTANTE:\n"
                "- Seja preciso na an√°lise emocional\n"
                "- Considere contexto cultural brasileiro\n" 
                "- Detecte sutilezas e entrelinhas\n"
                "- Priorize seguran√ßa em casos amb√≠guos"
            ),
            
            'gemini_system': (
                "Analise o sentimento emocional deste texto em portugu√™s brasileiro.\n"
                "Retorne um JSON com:\n"
                "- score: -1 a 1 (negativo/positivo)\n"
                "- confidence: 0 a 1\n"
                "- emotion: feliz, triste, ansioso, irritado, desesperado, vazio, neutro, esperan√ßoso, calmo\n"
                "- intensity: low, moderate, high\n"
                "Seja preciso e considere o contexto cultural brasileiro."
            )
        }
        
        # === INSTRU√á√ïES DE TOM POR N√çVEL DE RISCO ===
        self.tone_instructions = {
            'low': {
                'primary': "Seja emp√°tico, acolhedor e encorajador.",
                'details': "Mantenha tom leve e positivo, oferecendo suporte sem dramatizar."
            },
            'moderate': {
                'primary': "Seja emp√°tico e demonstre preocupa√ß√£o genu√≠na.",
                'details': "Mostre compreens√£o, valide sentimentos, sugira estrat√©gias pr√°ticas."
            },
            'high': {
                'primary': "Seja muito emp√°tico e encoraje buscar ajuda profissional.",
                'details': "Transmita urg√™ncia sem assustar, sugira recursos concretos."
            },
            'critical': {
                'primary': "Seja extremamente emp√°tico mas firme. Enfatize urg√™ncia de ajuda IMEDIATA.",
                'details': "Priorize seguran√ßa, seja direto sobre necessidade de ajuda profissional."
            }
        }
        
        # === PROMPTS BASE PARA DIFERENTES SITUA√á√ïES ===
        self.base_prompts = {
            'first_interaction': {
                'openai': self._get_first_interaction_prompt_openai(),
                'gemini': self._get_first_interaction_prompt_gemini()
            },
            'continuation': {
                'openai': self._get_continuation_prompt_openai(),
                'gemini': self._get_continuation_prompt_gemini()
            }
        }
        
        # === PROMPTS DE EMERG√äNCIA ===
        self.emergency_prompts = self._get_emergency_prompts()
        
        # === CONFIGURA√á√ïES DE PAR√ÇMETROS ===
        self.response_parameters = {
            'first_interaction_max_words': 80,
            'continuation_max_words': 100,
            'emergency_max_words': 120,
            'temperature_empathetic': 0.7,
            'temperature_analytical': 0.3
        }
    
    def get_sentiment_prompt(self, provider: str = 'openai') -> str:
        """
        Retorna prompt para an√°lise de sentimento
        
        Args:
            provider: 'openai' ou 'gemini'
            
        Returns:
            String com prompt formatado para an√°lise de sentimento
        """
        return self.sentiment_analysis_prompts.get(f'{provider}_system', 
                                                  self.sentiment_analysis_prompts['openai_system'])
    
    def build_conversation_prompt(self, 
                                user_message: str,
                                risk_level: str,
                                provider: str = 'openai',
                                user_context: Optional[Dict] = None,
                                conversation_history: Optional[List] = None,
                                rag_context: Optional[str] = None,
                                is_first_message: bool = False) -> Dict:
        """
        Constr√≥i prompt completo para gera√ß√£o de resposta
        
        Args:
            user_message: Mensagem do usu√°rio
            risk_level: N√≠vel de risco detectado
            provider: Provider de IA ('openai', 'gemini')
            user_context: Contexto do usu√°rio
            conversation_history: Hist√≥rico da conversa
            rag_context: Contexto do sistema RAG
            is_first_message: Se √© primeira intera√ß√£o
            
        Returns:
            Dict com prompt estruturado e metadados
        """
        # Extrair nome do usu√°rio
        user_name = ""
        if user_context and user_context.get('name'):
            user_name = user_context['name'].split()[0]
        
        # Selecionar template base
        template_type = 'first_interaction' if is_first_message else 'continuation'
        base_template = self.base_prompts[template_type][provider]
        
        # Construir prompt do sistema
        system_prompt = base_template.format(
            risk_level=risk_level.upper(),
            tone_instruction=self.tone_instructions[risk_level]['primary'],
            tone_details=self.tone_instructions[risk_level]['details'],
            user_name_instruction=f"Use o nome {user_name}" if user_name else "",
            max_words=self.response_parameters[f'{template_type}_max_words']
        )
        
        # Adicionar contexto RAG se dispon√≠vel
        if rag_context:
            system_prompt += f"\n\n{rag_context}"
        
        # Adicionar instru√ß√µes de emerg√™ncia para risco cr√≠tico
        if risk_level == 'critical':
            system_prompt += self.emergency_prompts['critical_instructions']
        
        # Construir estrutura de mensagens
        if provider == 'openai':
            messages = [{"role": "system", "content": system_prompt}]
            
            # Adicionar hist√≥rico limitado (√∫ltimas 6 mensagens)
            if conversation_history:
                recent_history = conversation_history[-6:]
                for msg in recent_history:
                    role = "user" if msg.get('message_type') == 'USER' else "assistant"
                    messages.append({"role": role, "content": msg.get('content', '')})
            
            # Mensagem atual
            messages.append({"role": "user", "content": user_message})
            
            return {
                'messages': messages,
                'temperature': self.response_parameters['temperature_empathetic'],
                'max_tokens': self._calculate_max_tokens(template_type, risk_level)
            }
        
        elif provider == 'gemini':
            # Gemini usa prompt √∫nico
            full_prompt = f"{system_prompt}\n\nMensagem do usu√°rio: {user_message}"
            
            return {
                'prompt': full_prompt,
                'temperature': self.response_parameters['temperature_empathetic']
            }
        
        else:
            raise ValueError(f"Provider '{provider}' n√£o suportado")
    
    def get_fallback_responses(self, risk_level: str, user_context: Optional[Dict] = None) -> List[str]:
        """
        Retorna respostas est√°ticas organizadas por n√≠vel de risco
        
        Args:
            risk_level: N√≠vel de risco detectado
            user_context: Contexto do usu√°rio para personaliza√ß√£o
            
        Returns:
            Lista de poss√≠veis respostas est√°ticas
        """
        user_name = ""
        if user_context and user_context.get('name'):
            user_name = user_context['name'].split()[0]
            name_prefix = f"{user_name}, " if user_name else ""
        else:
            name_prefix = ""
        
        fallback_responses = {
            'critical': [
                f"{name_prefix}estou muito preocupada com voc√™. Por favor, busque ajuda IMEDIATAMENTE. "
                "Ligue para o CVV: 188 (24h) ou v√° ao hospital. Voc√™ n√£o est√° sozinho(a). üö®",
                
                f"{name_prefix}percebo que voc√™ est√° em uma situa√ß√£o muito dif√≠cil. "
                "√â URGENTE que procure ajuda profissional agora. CVV: 188 (24h). N√£o hesite! ‚ö†Ô∏è",
                
                f"{name_prefix}sua seguran√ßa √© prioridade. Ligue AGORA para o CVV: 188 "
                "ou procure o hospital mais pr√≥ximo. Voc√™ merece ajuda e apoio. üÜò"
            ],
            
            'high': [
                f"{name_prefix}percebo que voc√™ est√° passando por um momento muito dif√≠cil. "
                "Considere conversar com um profissional ou ligar para o CVV: 188. üìû",
                
                f"{name_prefix}estou preocupada com como voc√™ est√° se sentindo. "
                "Buscar ajuda profissional pode fazer muita diferen√ßa. CVV: 188 est√° sempre dispon√≠vel. üíô",
                
                f"{name_prefix}suas palavras mostram uma dor profunda. "
                "Por favor, considere falar com um psic√≥logo ou ligar para o CVV: 188. Voc√™ n√£o est√° sozinho(a). ü§ù"
            ],
            
            'moderate': [
                f"{name_prefix}entendo que as coisas est√£o pesadas para voc√™. "
                "Lembre-se que √© normal ter altos e baixos. Quer conversar sobre isso? üí≠",
                
                f"{name_prefix}percebo que voc√™ est√° enfrentando desafios. "
                "√Äs vezes ajuda falar sobre o que est√° sentindo. Estou aqui para te ouvir. üëÇ",
                
                f"{name_prefix}momentos dif√≠ceis fazem parte da vida, mas n√£o precisamos enfrent√°-los sozinhos. "
                "Como posso te apoiar hoje? üåü"
            ],
            
            'low': [
                f"{name_prefix}estou aqui para te ouvir e apoiar. Como posso te ajudar hoje? üòä",
                
                f"{name_prefix}que bom ter voc√™ aqui! Conte-me o que est√° em sua mente. üíö",
                
                f"{name_prefix}estou dispon√≠vel para conversar sobre qualquer coisa que queira compartilhar. "
                "O que gostaria de falar? üó£Ô∏è"
            ]
        }
        
        return fallback_responses.get(risk_level, fallback_responses['low'])
    
    def _get_first_interaction_prompt_openai(self) -> str:
        """Template para primeira intera√ß√£o - OpenAI"""
        return """Voc√™ √© √çris, uma IA de apoio emocional especializada em portugu√™s brasileiro.

CONTEXTO: PRIMEIRA intera√ß√£o com este usu√°rio
N√çVEL DE RISCO: {risk_level}
INSTRU√á√ÉO DE TOM: {tone_instruction}
DETALHES: {tone_details}

DIRETRIZES PARA PRIMEIRA CONVERSA:
- Apresente-se brevemente como √çris
- Demonstre interesse genu√≠no e empatia
- Seja acolhedora e n√£o julgue
- Ofere√ßa apoio imediato
- Crie ambiente seguro para compartilhamento
- {user_name_instruction}

LIMITE: Responda em at√© {max_words} palavras
ESTILO: Natural, emp√°tico, brasileiro"""
    
    def _get_continuation_prompt_openai(self) -> str:
        """Template para continua√ß√£o de conversa - OpenAI"""
        return """Voc√™ √© √çris, continuando uma conversa de apoio emocional.

CONTEXTO: CONTINUA√á√ÉO da conversa
N√çVEL DE RISCO: {risk_level}
INSTRU√á√ÉO DE TOM: {tone_instruction}
DETALHES: {tone_details}

DIRETRIZES PARA CONTINUA√á√ÉO:
- Continue naturalmente, SEM se apresentar novamente
- Mantenha consist√™ncia com conversas anteriores
- Seja emp√°tica e ofere√ßa apoio espec√≠fico
- Fa√ßa perguntas abertas quando apropriado
- Valide sentimentos do usu√°rio
- {user_name_instruction}

LIMITE: Responda em at√© {max_words} palavras
ESTILO: Natural, emp√°tico, consistente"""
    
    def _get_first_interaction_prompt_gemini(self) -> str:
        """Template para primeira intera√ß√£o - Gemini"""
        return """Voc√™ √© √çris, IA de apoio emocional em portugu√™s brasileiro.

PRIMEIRA conversa. RISCO: {risk_level}
{tone_instruction} {tone_details}

Apresente-se brevemente e seja acolhedora.
{user_name_instruction}
M√°ximo {max_words} palavras."""
    
    def _get_continuation_prompt_gemini(self) -> str:
        """Template para continua√ß√£o - Gemini"""
        return """Voc√™ √© √çris, continuando conversa de apoio emocional.

RISCO: {risk_level}
{tone_instruction} {tone_details}

Continue naturalmente, sem se apresentar.
{user_name_instruction}
M√°ximo {max_words} palavras."""
    
    def _get_emergency_prompts(self) -> Dict:
        """Prompts espec√≠ficos para situa√ß√µes de emerg√™ncia"""
        return {
            'critical_instructions': """

‚ö†Ô∏è SITUA√á√ÉO DE RISCO CR√çTICO DETECTADA:
- Enfatize urg√™ncia de ajuda IMEDIATA
- Mencione CVV: 188 (24 horas)
- Sugira procurar hospital/pronto-socorro
- Seja firme mas emp√°tico
- N√ÉO minimize a situa√ß√£o
- Priorize seguran√ßa acima de tudo""",
            
            'crisis_contacts': {
                'cvv': "CVV - Centro de Valoriza√ß√£o da Vida: 188 (24h)",
                'samu': "SAMU: 192 (emerg√™ncias m√©dicas)",
                'emergency': "Em emerg√™ncia: v√° ao hospital mais pr√≥ximo"
            }
        }
    
    def _calculate_max_tokens(self, template_type: str, risk_level: str) -> int:
        """Calcula n√∫mero m√°ximo de tokens baseado no contexto"""
        base_tokens = {
            'first_interaction': 120,
            'continuation': 150
        }
        
        # Aumentar tokens para situa√ß√µes cr√≠ticas
        if risk_level == 'critical':
            return base_tokens.get(template_type, 150) + 50
        elif risk_level == 'high':
            return base_tokens.get(template_type, 150) + 30
        else:
            return base_tokens.get(template_type, 150)
    
    def get_provider_config(self, provider: str) -> Dict:
        """
        Retorna configura√ß√µes espec√≠ficas por provider
        
        Args:
            provider: Nome do provider ('openai', 'gemini')
            
        Returns:
            Dict com configura√ß√µes do provider
        """
        configs = {
            'openai': {
                'supports_system_message': True,
                'supports_conversation_history': True,
                'max_context_messages': 6,
                'preferred_temperature': 0.7,
                'supports_json_mode': True
            },
            'gemini': {
                'supports_system_message': False,
                'supports_conversation_history': False,
                'max_context_messages': 0,
                'preferred_temperature': 0.7,
                'supports_json_mode': False
            }
        }
        
        return configs.get(provider, configs['openai'])
    
    def validate_prompt_length(self, prompt: str, provider: str) -> bool:
        """
        Valida se o prompt est√° dentro dos limites do provider
        
        Args:
            prompt: Texto do prompt
            provider: Nome do provider
            
        Returns:
            True se v√°lido, False caso contr√°rio
        """
        limits = {
            'openai': 8000,  # Aproximadamente para gpt-4o-mini
            'gemini': 6000   # Aproximadamente para gemini-pro
        }
        
        # Estimativa simples: 4 caracteres por token
        estimated_tokens = len(prompt) // 4
        
        return estimated_tokens <= limits.get(provider, 8000)


# === FUN√á√ïES DE CONVENI√äNCIA ===

def create_prompt_manager() -> AIPromptManager:
    """Cria inst√¢ncia configurada do AIPromptManager"""
    return AIPromptManager()

# Inst√¢ncia global para uso direto
prompt_manager = AIPromptManager()

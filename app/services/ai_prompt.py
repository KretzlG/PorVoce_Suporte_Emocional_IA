# --- Regra de transi√ß√£o de risco ---
def validate_risk_transition(previous: "RiskLevel", new: "RiskLevel") -> "RiskLevel":
    """
    Garante que n√£o haja descida abrupta de 'critical' para 'low'.
    Se anterior era 'critical', s√≥ permite 'critical' ou 'high'.
    Caso contr√°rio, retorna o anterior.
    """
    if previous == RiskLevel.CRITICAL and new in [RiskLevel.LOW, RiskLevel.MODERATE]:
        # Mant√©m 'critical' ou permite apenas 'high'
        return RiskLevel.HIGH if new == RiskLevel.HIGH else RiskLevel.CRITICAL
    return new

# Sistema de Prompts para IA de Suporte Emocional
# Centraliza templates, instru√ß√µes e configura√ß√µes de tom
# Refatorado para facilitar manuten√ß√£o e extens√£o

import logging
from typing import Dict, Optional, List, Tuple
from dataclasses import dataclass
from enum import Enum

logger = logging.getLogger(__name__)


class PromptType(Enum):
    EMPATHETIC_RESPONSE = "empathetic_response"
    CRISIS_INTERVENTION = "crisis_intervention"
    COGNITIVE_BEHAVIORAL = "cognitive_behavioral"
    MINDFULNESS_BASED = "mindfulness_based"
    SOLUTION_FOCUSED = "solution_focused"



class RiskLevel(Enum):
    LOW = "low"
    MODERATE = "moderate"
    HIGH = "high"
    CRITICAL = "critical"

# --- Regra de transi√ß√£o de risco ---
def validate_risk_transition(previous: RiskLevel, new: RiskLevel) -> RiskLevel:
    """
    Garante que n√£o haja descida abrupta de 'critical' para 'low'.
    Se anterior era 'critical', s√≥ permite 'critical' ou 'high'.
    Caso contr√°rio, retorna o anterior.
    """
    if previous == RiskLevel.CRITICAL and new in [RiskLevel.LOW, RiskLevel.MODERATE]:
        # Mant√©m 'critical' ou permite apenas 'high'
        return RiskLevel.HIGH if new == RiskLevel.HIGH else RiskLevel.CRITICAL
    return new


@dataclass
class PromptContext:
    user_message: str
    risk_level: RiskLevel
    user_name: Optional[str] = None
    session_history: Optional[List[Dict]] = None
    training_context: Optional[str] = None
    conversation_examples: Optional[List[Dict]] = None
    emotional_state: Optional[str] = None
    dominant_themes: Optional[List[str]] = None
    therapeutic_approach: Optional[PromptType] = None


class AIPromptManager:
    """
    Gerenciador central dos prompts e regras de resposta da IA.
    Coment√°rios orientam manuten√ß√£o e extens√£o.
    """
    def __init__(self):
        # Templates e estrat√©gias
        self.prompt_templates = self._initialize_templates()
        self.therapeutic_strategies = self._initialize_therapeutic_strategies()
        self.risk_adaptations = self._initialize_risk_adaptations()

        # Prompts para an√°lise de sentimento
        self.sentiment_analysis_prompts = {
            'openai_system': (
                "Voc√™ √© um especialista em an√°lise de sentimento emocional em portugu√™s brasileiro.\n"
                "Retorne APENAS um JSON v√°lido com score, confidence, emotion e intensity.\n"
                "Considere contexto cultural brasileiro e priorize seguran√ßa."
            ),
            'gemini_system': (
                "Analise o sentimento emocional em portugu√™s brasileiro.\n"
                "Retorne JSON com score, confidence, emotion e intensity."
            )
        }

        # Instru√ß√µes de tom por n√≠vel de risco
        self.tone_instructions = {
            'low': {'primary': "Seja otimista.", 'details': "Energia positiva."},
            'moderate': {'primary': "Compreensiva e firme.", 'details': "Valide e direcione."},
            'high': {'primary': "Carinhosa e direta.", 'details': "Urg√™ncia com esperan√ßa."},
            'critical': {'primary': "Firme e protetiva.", 'details': "Seguran√ßa em primeiro lugar."}
        }

        # Prompts base para situa√ß√µes
        self.base_prompts = {
            'first_interaction': {
                'openai': self._get_first_interaction_prompt_openai(),
                'gemini': self._get_first_interaction_prompt_gemini()
            },
            'continuation': {
                'openai': self._get_continuation_prompt_openai(),
                'gemini': self._get_continuation_prompt_gemini()
            }
        }

        # Prompts de emerg√™ncia
        self.emergency_prompts = self._get_emergency_prompts()

        # Par√¢metros de resposta
        self.response_parameters = {
            'first_interaction_max_words': 40,
            'continuation_max_words': 50,
            'emergency_max_words': 60,
            'temperature_empathetic': 0.8,
            'temperature_analytical': 0.3
        }
    
    # --- M√©todos principais ---
    def get_sentiment_prompt(self, provider: str = 'openai') -> str:
        """Retorna prompt para an√°lise de sentimento."""
        return self.sentiment_analysis_prompts.get(f'{provider}_system', self.sentiment_analysis_prompts['openai_system'])
    
    def build_contextual_prompt(self, context: PromptContext, provider: str = 'openai') -> Dict:
        """Constr√≥i prompt contextualizado baseado no contexto fornecido."""
        try:
            therapeutic_approach = self._determine_therapeutic_approach(context)
            prompt_sections = self._build_prompt_sections(context, therapeutic_approach)
            if context.training_context:
                prompt_sections['training_integration'] = self._integrate_training_data(context.training_context, context.risk_level)
            if context.conversation_examples:
                prompt_sections['conversation_examples'] = self._format_conversation_examples(context.conversation_examples, context.risk_level)
            if provider == 'openai':
                return self._build_openai_prompt(prompt_sections, context)
            elif provider == 'gemini':
                return self._build_gemini_prompt(prompt_sections, context)
            else:
                return self._build_generic_prompt(prompt_sections, context)
        except Exception as e:
            logger.error(f"Erro na constru√ß√£o do prompt: {e}")
            return self._build_fallback_prompt(context, provider)
    
    def build_conversation_prompt(self, user_message: str, risk_level: str, provider: str = 'openai', user_context: Optional[Dict] = None, conversation_history: Optional[List] = None, rag_context: Optional[str] = None, is_first_message: bool = False) -> Dict:
        """Constr√≥i prompt completo para gera√ß√£o de resposta."""
        user_name = user_context['name'].split()[0] if user_context and user_context.get('name') else ""
        conversation_mood = self._analyze_conversation_mood(conversation_history)
        adaptation_rules = self._get_adaptation_rules(conversation_mood, risk_level)
        template_type = 'first_interaction' if is_first_message else 'continuation'
        base_template = self.base_prompts[template_type][provider]
        system_prompt = base_template.format(
            risk_level=risk_level.upper(),
            tone_instruction=self.tone_instructions[risk_level]['primary'],
            tone_details=self.tone_instructions[risk_level]['details'],
            user_name_instruction=f"Use {user_name}" if user_name else "",
            max_words=self.response_parameters[f'{template_type}_max_words']
        )
        if adaptation_rules:
            system_prompt += f"\n\nADAPTA√á√ÉO: {adaptation_rules}"
        if rag_context:
            system_prompt += f"\n\n{rag_context}"
        if risk_level == 'critical':
            system_prompt += self.emergency_prompts['critical_instructions']
        if provider == 'openai':
            messages = [{"role": "system", "content": system_prompt}]
            if conversation_history:
                for msg in conversation_history[-4:]:
                    role = "user" if msg.get('message_type') == 'USER' else "assistant"
                    messages.append({"role": role, "content": msg.get('content', '')})
            messages.append({"role": "user", "content": user_message})
            return {
                'messages': messages,
                'temperature': self.response_parameters['temperature_empathetic'],
                'max_tokens': self._calculate_max_tokens(template_type, risk_level)
            }
        elif provider == 'gemini':
            full_prompt = f"{system_prompt}\n\nMensagem do usu√°rio: {user_message}"
            return {
                'prompt': full_prompt,
                'temperature': self.response_parameters['temperature_empathetic']
            }
        else:
            raise ValueError(f"Provider '{provider}' n√£o suportado")
    
    def get_fallback_responses(self, risk_level: str, user_context: Optional[Dict] = None) -> List[str]:
        """Retorna respostas est√°ticas por n√≠vel de risco."""
        user_name = user_context['name'].split()[0] if user_context and user_context.get('name') else ""
        name_prefix = f"{user_name}, " if user_name else ""
        fallback_responses = {
            'critical': [
                f"{name_prefix}SITUA√á√ÉO CR√çTICA DETECTADA! Nossa equipe foi acionada. üö®",
                f"{name_prefix}TRIAGEM EMERGENCIAL ATIVADA! Profissional em contato. ‚ö†Ô∏è",
                f"{name_prefix}VOC√ä N√ÉO EST√Å SOZINHO! Atendimento de crise AGORA. üÜò"
            ],
            'high': [
                f"{name_prefix}nossa triagem ir√° te atender. Voc√™ merece suporte! üí™",
                f"{name_prefix}conectando com profissionais. Voc√™ tem for√ßa! üåü",
                f"{name_prefix}protocolo de apoio intensivo ativado. Dias melhores vir√£o! ‚òÄÔ∏è"
            ],
            'moderate': [
                f"{name_prefix}suporte mais direcionado dispon√≠vel! O que pode fazer hoje? üí≠",
                f"{name_prefix}voc√™ √© forte. Vamos conectar recursos internos? üåü",
                f"{name_prefix}isso vai passar! Triagem pode organizar acompanhamento. ‚ú®"
            ],
            'low': [
                f"{name_prefix}que bom ter voc√™ aqui! Como posso apoiar? üòä",
                f"{name_prefix}oi! Como est√° se sentindo? üíö",
                f"{name_prefix}estou aqui para ouvir! O que est√° acontecendo? üó£Ô∏è"
            ]
        }
        return fallback_responses.get(risk_level, fallback_responses['low'])
    
    def _get_first_interaction_prompt_openai(self) -> str:
        """Template para primeira intera√ß√£o - OpenAI"""
        return """Voc√™ √© √çris, assistente de apoio emocional brasileira.

PRIMEIRA CONVERSA | RISCO: {risk_level}
{tone_instruction} {tone_details}

REGRAS R√çGIDAS:
- NUNCA se apresente ap√≥s a primeira frase
- NUNCA pe√ßa desculpas desnecessariamente  
- NUNCA diga "entendo que", "sei que √© dif√≠cil"
- FOQUE na pessoa, n√£o em voc√™
- Seja DIRETA e PR√ÅTICA
- Use energia POSITIVA sempre que poss√≠vel
{user_name_instruction}

M√ÅXIMO {max_words} palavras. Seja concisa e eficaz."""
    
    def _get_continuation_prompt_openai(self) -> str:
        """Template para continua√ß√£o de conversa - OpenAI"""
        return """Continue como √çris em conversa em andamento.

CONVERSA CONTINUADA | RISCO: {risk_level}
{tone_instruction} {tone_details}

REGRAS OBRIGAT√ìRIAS:
- NUNCA se apresente novamente
- NUNCA repita frases como "estou aqui para", "sinto muito"
- Responda DIRETAMENTE ao que foi dito
- Adapte seu tom ao ESTADO EMOCIONAL atual
- Seja PR√ÅTICA e SOLUCIONADORA
- Use ENERGIA para motivar
- ENCORAJE a buscar ajuda profissional atrav√©s da rota de triagem
{user_name_instruction}

M√ÅXIMO {max_words} palavras. V√° direto ao ponto."""
    
    def _get_first_interaction_prompt_gemini(self) -> str:
        """Template para primeira intera√ß√£o - Gemini"""
        return """Voc√™ √© √çris, IA de apoio emocional em portugu√™s brasileiro.

PRIMEIRA conversa. RISCO: {risk_level}
{tone_instruction} {tone_details}

Apresente-se brevemente e seja acolhedora.
{user_name_instruction}
M√°ximo {max_words} palavras."""
    
    def _get_continuation_prompt_gemini(self) -> str:
        """Template para continua√ß√£o - Gemini"""
        return """Voc√™ √© √çris, continuando conversa de apoio emocional.

RISCO: {risk_level}
{tone_instruction} {tone_details}

Continue naturalmente, sem se apresentar.
{user_name_instruction}
M√°ximo {max_words} palavras."""
    
    def _get_emergency_prompts(self) -> Dict:
        """Prompts espec√≠ficos para situa√ß√µes de emerg√™ncia"""
        return {
            'critical_instructions': """

‚ö†Ô∏è SITUA√á√ÉO DE RISCO CR√çTICO DETECTADA:
- Enfatize urg√™ncia de ajuda IMEDIATA
- Ative triagem emergencial interna
- Sugira procurar hospital/pronto-socorro
- Seja firme mas emp√°tico
- N√ÉO minimize a situa√ß√£o
- Priorize seguran√ßa acima de tudo""",
            
            'crisis_contacts': {
                'triagem_interna': "Triagem Especializada - Equipe interna dispon√≠vel 24h"
            }
        }
    
    def _calculate_max_tokens(self, template_type: str, risk_level: str) -> int:
        """Calcula n√∫mero m√°ximo de tokens baseado no contexto"""
        base_tokens = {
            'first_interaction': 80,
            'continuation': 100
        }
        
        # Aumentar tokens apenas para situa√ß√µes cr√≠ticas
        if risk_level == 'critical':
            return base_tokens.get(template_type, 100) + 30
        elif risk_level == 'high':
            return base_tokens.get(template_type, 100) + 20
        else:
            return base_tokens.get(template_type, 100)
    
    def get_provider_config(self, provider: str) -> Dict:
        """Retorna configura√ß√µes espec√≠ficas por provider."""
        configs = {
            'openai': {'supports_system_message': True, 'supports_conversation_history': True, 'max_context_messages': 6, 'preferred_temperature': 0.7, 'supports_json_mode': True},
            'gemini': {'supports_system_message': False, 'supports_conversation_history': False, 'max_context_messages': 0, 'preferred_temperature': 0.7, 'supports_json_mode': False}
        }
        return configs.get(provider, configs['openai'])
    
    def _analyze_conversation_mood(self, conversation_history: Optional[List]) -> str:
        """
        Analisa o humor geral da conversa para adapta√ß√£o din√¢mica
        
        Args:
            conversation_history: Hist√≥rico das mensagens
            
        Returns:
            String indicando o humor: 'improving', 'worsening', 'stable', 'crisis', 'unknown'
        """
        if not conversation_history or len(conversation_history) < 3:
            return 'unknown'
        
        try:
            # Analisa as √∫ltimas 4 mensagens do usu√°rio
            user_messages = [
                msg for msg in conversation_history[-6:] 
                if msg.get('message_type') == 'USER'
            ][-4:]
            
            if len(user_messages) < 2:
                return 'unknown'
            
            # Palavras que indicam melhora
            improvement_words = [
                'melhor', 'melhorando', 'obrigado', 'ajudou', 'consegui', 
                'tentando', 'for√ßa', 'esperan√ßa', 'positivo', 'bem'
            ]
            
            # Palavras que indicam piora
            worsening_words = [
                'pior', 'piorando', 'desistir', 'acabou', 'imposs√≠vel', 
                'n√£o aguento', 'sem sa√≠da', 'desespero', 'vazio'
            ]
            
            # Palavras de crise
            crisis_words = [
                'morrer', 'suic√≠dio', 'acabar com tudo', 'n√£o quero viver',
                'me matar', 'melhor morto'
            ]
            
            improvement_score = 0
            worsening_score = 0
            crisis_score = 0
            
            for msg in user_messages:
                content = msg.get('content', '').lower()
                
                improvement_score += sum(1 for word in improvement_words if word in content)
                worsening_score += sum(1 for word in worsening_words if word in content)
                crisis_score += sum(1 for word in crisis_words if word in content)
            
            # Determinar humor
            if crisis_score > 0:
                return 'crisis'
            elif improvement_score > worsening_score:
                return 'improving'
            elif worsening_score > improvement_score:
                return 'worsening'
            else:
                return 'stable'
                
        except Exception:
            return 'unknown'
    
    def _get_adaptation_rules(self, conversation_mood: str, risk_level: str) -> str:
        """
        Retorna regras de adapta√ß√£o baseadas no humor da conversa
        
        Args:
            conversation_mood: Humor detectado da conversa
            risk_level: N√≠vel de risco atual
            
        Returns:
            String com regras espec√≠ficas de adapta√ß√£o
        """
        adaptations = {
            'improving': "Pessoa est√° melhorando! Reforce progresso, seja AINDA MAIS POSITIVA e encorajadora. Celebre pequenas vit√≥rias!",
            
            'worsening': "Situa√ß√£o piorando. Seja mais FIRME e DIRETA sobre buscar ajuda. Aumente energia positiva para contrabalan√ßar.",
            
            'crisis': "CRISE DETECTADA. Seja EXTREMAMENTE DIRETA sobre buscar ajuda IMEDIATA. Priorize seguran√ßa acima de tudo.",
            
            'stable': "Conversa est√°vel. Mantenha tom consistente e foque em pequenos passos para frente.",
            
            'unknown': "Primeira conversa ou dados insuficientes. Seja calorosa mas n√£o excessiva."
        }
        
        adaptation = adaptations.get(conversation_mood, '')
        
        # Ajustes espec√≠ficos por risco
        if risk_level == 'critical' and conversation_mood != 'improving':
            adaptation += " REFORCE urg√™ncia de ajuda profissional."
        elif risk_level == 'low' and conversation_mood == 'improving':
            adaptation += " Use mais humor e leveza."
            
        return adaptation
    
    def validate_prompt_length(self, prompt: str, provider: str) -> bool:
        """Valida se o prompt est√° dentro dos limites do provider."""
        limits = {'openai': 8000, 'gemini': 6000}
        estimated_tokens = len(prompt) // 4
        return estimated_tokens <= limits.get(provider, 8000)
    
    # === M√âTODOS AVAN√áADOS (INTEGRADOS DO ADVANCED PROMPT ENGINEER) ===
    
    def _initialize_templates(self) -> Dict:
        """Inicializa templates base de prompts"""
        return {
            'system_base': """Voc√™ √© um assistente especializado em suporte emocional e bem-estar mental. 
Suas respostas devem ser:
- Emp√°ticas e compreensivas
- Baseadas em evid√™ncias cient√≠ficas
- Pr√°ticas e aplic√°veis
- Respeitosas e n√£o-julgamentais
- Orientadas para solu√ß√µes quando apropriado

IMPORTANTE: Sempre priorize a seguran√ßa. Em casos de risco alto, encoraje busca por ajuda profissional.""",

            'risk_critical': """‚ö†Ô∏è PROTOCOLO DE CRISE ATIVADO ‚ö†Ô∏è
Esta pessoa pode estar em risco imediato. Sua resposta deve:
1. Validar os sentimentos sem minimizar
2. Oferecer recursos de emerg√™ncia imediatos
3. Encorajar contato com profissionais
4. Demonstrar que a vida tem valor
5. Sugerir estrat√©gias de seguran√ßa imediata

RECURSOS DE EMERG√äNCIA:
- CVV: 188 (24h, gratuito)
- SAMU: 192
- Bombeiros: 193""",

            'empathetic_foundation': """Responda com profunda empatia, reconhecendo que:
- Os sentimentos da pessoa s√£o v√°lidos e compreens√≠veis
- Cada experi√™ncia √© √∫nica e significativa
- N√£o h√° julgamento, apenas acolhimento
- O sofrimento merece ser ouvido e compreendido""",

            'solution_focused': """Mantenha foco nas solu√ß√µes e recursos, explorando:
- For√ßas e recursos internos da pessoa
- Momentos de exce√ß√£o (quando o problema n√£o estava presente)
- Pequenos passos pr√°ticos e alcan√ß√°veis
- Objetivos claros e mensur√°veis""",

            'cognitive_behavioral': """Aplique princ√≠pios da Terapia Cognitivo-Comportamental:
- Identifique padr√µes de pensamento
- Questione pensamentos autom√°ticos negativos
- Conecte pensamentos, sentimentos e comportamentos
- Sugira experimentos comportamentais pequenos""",

            'mindfulness_integration': """Integre elementos de mindfulness:
- Aten√ß√£o ao momento presente
- Aceita√ß√£o sem julgamento
- T√©cnicas de respira√ß√£o e grounding
- Observa√ß√£o dos pensamentos sem identifica√ß√£o total"""
        }
    
    def _initialize_therapeutic_strategies(self) -> Dict:
        """Inicializa estrat√©gias terap√™uticas espec√≠ficas"""
        return {
            PromptType.EMPATHETIC_RESPONSE: {
                'focus': 'valida√ß√£o e acolhimento emocional',
                'techniques': ['escuta ativa', 'reflexo de sentimentos', 'normaliza√ß√£o'],
                'phrases': [
                    "Entendo que voc√™ est√° passando por um momento muito dif√≠cil",
                    "Seus sentimentos s√£o completamente compreens√≠veis nesta situa√ß√£o",
                    "N√£o est√° sozinho(a) neste processo"
                ]
            },
            
            PromptType.CRISIS_INTERVENTION: {
                'focus': 'seguran√ßa imediata e estabiliza√ß√£o',
                'techniques': ['avalia√ß√£o de risco', 'plano de seguran√ßa', 'recursos de emerg√™ncia'],
                'phrases': [
                    "Sua vida tem valor e import√¢ncia",
                    "Existem pessoas que podem ajudar agora mesmo",
                    "Este momento dif√≠cil pode passar"
                ]
            },
            
            PromptType.COGNITIVE_BEHAVIORAL: {
                'focus': 'identifica√ß√£o e modifica√ß√£o de padr√µes de pensamento',
                'techniques': ['reestrutura√ß√£o cognitiva', 'experimentos comportamentais', 'automonitoramento'],
                'phrases': [
                    "Vamos examinar este pensamento mais de perto",
                    "Que evid√™ncias apoiam ou contradizem esta ideia?",
                    "Como voc√™ poderia testar se isso √© realmente verdade?"
                ]
            },
            
            PromptType.MINDFULNESS_BASED: {
                'focus': 'consci√™ncia presente e aceita√ß√£o',
                'techniques': ['respira√ß√£o consciente', 'body scan', 'observa√ß√£o sem julgamento'],
                'phrases': [
                    "Vamos focar no que voc√™ pode sentir neste momento",
                    "Notice estes pensamentos como nuvens passando no c√©u",
                    "Respire profundamente e volte ao momento presente"
                ]
            },
            
            PromptType.SOLUTION_FOCUSED: {
                'focus': 'recursos internos e solu√ß√µes pr√°ticas',
                'techniques': ['escala de bem-estar', 'perguntas do milagre', 'exce√ß√µes'],
                'phrases': [
                    "Quando voc√™ j√° lidou bem com algo similar?",
                    "Que recursos internos voc√™ tem para enfrentar isso?",
                    "Qual seria um pequeno primeiro passo?"
                ]
            }
        }
    
    def _initialize_risk_adaptations(self) -> Dict:
        """Inicializa adapta√ß√µes espec√≠ficas por n√≠vel de risco"""
        return {
            RiskLevel.LOW: {
                'tone': 'encorajador e explorat√≥rio',
                'focus': 'crescimento e desenvolvimento',
                'suggestions': ['autoconhecimento', 'metas pessoais', 'bem-estar preventivo']
            },
            
            RiskLevel.MODERATE: {
                'tone': 'solid√°rio e pr√°tico',
                'focus': 'estrat√©gias de enfrentamento',
                'suggestions': ['t√©cnicas de manejo', 'suporte social', 'atividades regulares']
            },
            
            RiskLevel.HIGH: {
                'tone': 'cuidadoso e direcionado',
                'focus': 'estabiliza√ß√£o e suporte',
                'suggestions': ['ajuda profissional', 'rede de apoio', 'cuidados imediatos']
            },
            
            RiskLevel.CRITICAL: {
                'tone': 'urgente mas acolhedor',
                'focus': 'seguran√ßa imediata',
                'suggestions': ['emerg√™ncia m√©dica', 'acompanhamento constante', 'hospitaliza√ß√£o se necess√°rio']
            }
        }
    
    def _determine_therapeutic_approach(self, context: PromptContext) -> PromptType:
        """Determina a melhor abordagem terap√™utica baseada no contexto"""
        
        # Casos cr√≠ticos sempre usam interven√ß√£o de crise
        if context.risk_level == RiskLevel.CRITICAL:
            return PromptType.CRISIS_INTERVENTION
        
        # Se h√° abordagem espec√≠fica solicitada
        if context.therapeutic_approach:
            return context.therapeutic_approach
        
        # Baseado no conte√∫do da mensagem
        message_lower = context.user_message.lower()
        
        # Indicadores para diferentes abordagens
        cognitive_indicators = ['penso que', 'acredito que', 'tenho certeza', 'sempre acontece', 'nunca consigo']
        mindfulness_indicators = ['ansioso', 'acelerado', 'mente correndo', 'n√£o paro de pensar']
        solution_indicators = ['o que fazer', 'como resolver', 'preciso de ajuda para', 'n√£o sei como']
        
        # Contar indicadores
        cognitive_score = sum(1 for indicator in cognitive_indicators if indicator in message_lower)
        mindfulness_score = sum(1 for indicator in mindfulness_indicators if indicator in message_lower)
        solution_score = sum(1 for indicator in solution_indicators if indicator in message_lower)
        
        # Determinar abordagem
        if solution_score >= 2:
            return PromptType.SOLUTION_FOCUSED
        elif cognitive_score >= 2:
            return PromptType.COGNITIVE_BEHAVIORAL
        elif mindfulness_score >= 2:
            return PromptType.MINDFULNESS_BASED
        elif context.risk_level == RiskLevel.HIGH:
            return PromptType.CRISIS_INTERVENTION
        else:
            return PromptType.EMPATHETIC_RESPONSE
    
    def _build_prompt_sections(self, context: PromptContext, 
                              therapeutic_approach: PromptType) -> Dict:
        """Constr√≥i se√ß√µes espec√≠ficas do prompt"""
        
        sections = {}
        
        # 1. Sistema base
        sections['system_base'] = self.prompt_templates['system_base']
        
        # 2. Adapta√ß√£o por risco
        risk_adaptation = self.risk_adaptations[context.risk_level]
        sections['risk_adaptation'] = f"""
N√çVEL DE RISCO: {context.risk_level.value.upper()}
Tom da resposta: {risk_adaptation['tone']}
Foco principal: {risk_adaptation['focus']}
Sugest√µes priorit√°rias: {', '.join(risk_adaptation['suggestions'])}
"""
        
        # 3. Estrat√©gia terap√™utica
        strategy = self.therapeutic_strategies[therapeutic_approach]
        sections['therapeutic_strategy'] = f"""
ABORDAGEM TERAP√äUTICA: {therapeutic_approach.value}
Foco: {strategy['focus']}
T√©cnicas: {', '.join(strategy['techniques'])}

Frases √∫teis para incorporar:
{chr(10).join(['- ' + phrase for phrase in strategy['phrases']])}
"""
        
        # 4. Protocolo espec√≠fico para risco cr√≠tico
        if context.risk_level == RiskLevel.CRITICAL:
            sections['crisis_protocol'] = self.prompt_templates['risk_critical']
        
        # 5. Contexto do usu√°rio
        if context.user_name:
            sections['user_context'] = f"Nome do usu√°rio: {context.user_name}"
        
        # 6. Estado emocional se conhecido
        if context.emotional_state:
            sections['emotional_context'] = f"Estado emocional identificado: {context.emotional_state}"
        
        # 7. Temas dominantes se identificados
        if context.dominant_themes:
            sections['themes_context'] = f"Temas principais: {', '.join(context.dominant_themes)}"
        
        return sections
    
    def _integrate_training_data(self, training_context: str, risk_level: RiskLevel) -> str:
        """Integra dados de treinamento ao prompt"""
        
        integration = f"""
=== CONHECIMENTO ESPECIALIZADO RELEVANTE ===
{training_context}

INSTRU√á√ïES PARA USO:
- Use este conhecimento como base cient√≠fica para sua resposta
- Adapte as informa√ß√µes para o contexto espec√≠fico do usu√°rio
- Mantenha linguagem acess√≠vel e n√£o t√©cnica
- Priorize aspectos mais relevantes para o n√≠vel de risco {risk_level.value}
"""
        
        if risk_level in [RiskLevel.HIGH, RiskLevel.CRITICAL]:
            integration += "\n- FOQUE em informa√ß√µes sobre seguran√ßa e recursos de emerg√™ncia"
        
        return integration
    
    def _format_conversation_examples(self, conversation_examples: List[Dict], 
                                    risk_level: RiskLevel) -> str:
        """Formata exemplos de conversas bem-sucedidas"""
        
        if not conversation_examples:
            return ""
        
        formatted = "=== EXEMPLOS DE RESPOSTAS EFICAZES ===\\n"
        
        for i, example in enumerate(conversation_examples[:2], 1):  # M√°ximo 2 exemplos
            rating = "‚≠ê" * int(example.get('rating', 3))
            formatted += f"""
üí¨ Exemplo {i} ({rating}):
Situa√ß√£o: {example.get('user_message', '')}
Resposta eficaz: {example.get('ai_response', '')}
Por que funcionou: Abordagem {example.get('risk_level', 'adequada')} para o contexto
"""
        
        formatted += """
COMO USAR ESTES EXEMPLOS:
- Inspire-se no tom e abordagem, mas personalize para o caso atual
- Note como as respostas eficazes equilibram empatia com orienta√ß√£o pr√°tica
- Adapte o n√≠vel de interven√ß√£o para o risco identificado
"""
        
        return formatted
    
    def _build_openai_prompt(self, sections: Dict, context: PromptContext) -> Dict:
        """Constr√≥i prompt espec√≠fico para OpenAI"""
        
        # Mensagem do sistema
        system_parts = [sections['system_base']]
        
        if 'crisis_protocol' in sections:
            system_parts.append(sections['crisis_protocol'])
        
        system_parts.append(sections['risk_adaptation'])
        system_parts.append(sections['therapeutic_strategy'])
        
        if 'training_integration' in sections:
            system_parts.append(sections['training_integration'])
        
        if 'conversation_examples' in sections:
            system_parts.append(sections['conversation_examples'])
        
        # Instru√ß√µes finais
        system_parts.append("""
INSTRU√á√ïES FINAIS:
1. Responda de forma calorosa e humana
2. Use no m√°ximo 200-300 palavras
3. Ofere√ßa pelo menos uma sugest√£o pr√°tica
4. Termine com uma pergunta aberta ou convite para continuar a conversa
5. Se risco alto/cr√≠tico, SEMPRE mencione recursos profissionais
""")
        
        # Contexto adicional do usu√°rio
        if any(k in sections for k in ['user_context', 'emotional_context', 'themes_context']):
            context_info = []
            for key in ['user_context', 'emotional_context', 'themes_context']:
                if key in sections:
                    context_info.append(sections[key])
            system_parts.append("CONTEXTO DO USU√ÅRIO:\\n" + "\\n".join(context_info))
        
        # Mensagens
        messages = [
            {"role": "system", "content": "\\n\\n".join(system_parts)},
            {"role": "user", "content": context.user_message}
        ]
        
        # Hist√≥rico da conversa se dispon√≠vel
        if context.session_history:
            # Inserir hist√≥rico antes da mensagem atual
            history_messages = []
            for msg in context.session_history[-6:]:  # √öltimas 6 mensagens
                if msg.get('role') in ['user', 'assistant']:
                    history_messages.append({
                        "role": msg['role'],
                        "content": msg['content']
                    })
            
            messages = [messages[0]] + history_messages + [messages[1]]
        
        return {
            'messages': messages,
            'max_tokens': 400 if context.risk_level in [RiskLevel.HIGH, RiskLevel.CRITICAL] else 300,
            'temperature': 0.7,
            'presence_penalty': 0.1,
            'frequency_penalty': 0.1
        }
    
    def _build_gemini_prompt(self, sections: Dict, context: PromptContext) -> Dict:
        """Constr√≥i prompt espec√≠fico para Gemini"""
        
        prompt_parts = []
        
        # Sistema e instru√ß√µes principais
        prompt_parts.append(sections['system_base'])
        prompt_parts.append(sections['risk_adaptation'])
        prompt_parts.append(sections['therapeutic_strategy'])
        
        # Protocolo de crise se necess√°rio
        if 'crisis_protocol' in sections:
            prompt_parts.append(sections['crisis_protocol'])
        
        # Dados de treinamento
        if 'training_integration' in sections:
            prompt_parts.append(sections['training_integration'])
        
        # Exemplos de conversas
        if 'conversation_examples' in sections:
            prompt_parts.append(sections['conversation_examples'])
        
        # Contexto do usu√°rio
        if any(k in sections for k in ['user_context', 'emotional_context', 'themes_context']):
            context_info = []
            for key in ['user_context', 'emotional_context', 'themes_context']:
                if key in sections:
                    context_info.append(sections[key])
            prompt_parts.append("CONTEXTO DO USU√ÅRIO:\\n" + "\\n".join(context_info))
        
        # Mensagem do usu√°rio
        prompt_parts.append(f"\\nMENSAGEM DO USU√ÅRIO:\\n{context.user_message}")
        
        # Instru√ß√µes de resposta
        prompt_parts.append("""
RESPONDA AGORA:
- Com empatia e compreens√£o
- De forma pr√°tica e √∫til
- Respeitando o n√≠vel de risco identificado
- Em portugu√™s brasileiro
- Com no m√°ximo 250 palavras
""")
        
        return {
            'prompt': "\\n\\n".join(prompt_parts),
            'max_tokens': 350,
            'temperature': 0.7
        }
    
    def _build_generic_prompt(self, sections: Dict, context: PromptContext) -> Dict:
        """Constr√≥i prompt gen√©rico para outros provedores"""
        return self._build_gemini_prompt(sections, context)
    
    def _build_fallback_prompt(self, context: PromptContext, provider: str) -> Dict:
        """Constr√≥i prompt de fallback em caso de erro"""
        
        fallback_system = f"""Voc√™ √© um assistente de suporte emocional. 
Responda com empatia para esta situa√ß√£o de n√≠vel de risco {context.risk_level.value}.
Seja compreensivo, pr√°tico e ofere√ßa apoio genu√≠no."""
        
        if provider == 'openai':
            return {
                'messages': [
                    {"role": "system", "content": fallback_system},
                    {"role": "user", "content": context.user_message}
                ],
                'max_tokens': 250,
                'temperature': 0.7
            }
        else:
            return {
                'prompt': f"{fallback_system}\\n\\nUsu√°rio: {context.user_message}\\n\\nResposta:",
                'max_tokens': 250,
                'temperature': 0.7
            }
    
    def get_prompt_statistics(self) -> Dict:
        """Retorna estat√≠sticas sobre uso de prompts"""
        return {
            'available_prompt_types': [pt.value for pt in PromptType],
            'risk_levels': [rl.value for rl in RiskLevel],
            'templates_count': len(self.prompt_templates),
            'strategies_count': len(self.therapeutic_strategies),
            'risk_adaptations_count': len(self.risk_adaptations)
        }
    
    def validate_prompt_context(self, context: PromptContext) -> Tuple[bool, List[str]]:
        """Valida se o contexto do prompt est√° completo"""
        
        errors = []
        
        if not context.user_message or not context.user_message.strip():
            errors.append("Mensagem do usu√°rio n√£o pode estar vazia")
        
        if not isinstance(context.risk_level, RiskLevel):
            errors.append("N√≠vel de risco deve ser um RiskLevel v√°lido")
        
        if context.session_history and not isinstance(context.session_history, list):
            errors.append("Hist√≥rico da sess√£o deve ser uma lista")
        
        if context.dominant_themes and not isinstance(context.dominant_themes, list):
            errors.append("Temas dominantes devem ser uma lista")
        
        return len(errors) == 0, errors


# --- Fun√ß√µes de conveni√™ncia ---
def create_prompt_manager() -> AIPromptManager:
    """Cria inst√¢ncia configurada do AIPromptManager."""
    return AIPromptManager()

# Inst√¢ncia global para uso direto
prompt_manager = AIPromptManager()
